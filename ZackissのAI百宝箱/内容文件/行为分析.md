# è¡Œä¸ºåˆ†æ

### ä¸»æˆåˆ†åˆ†æ

- é›†ç¾¤è¿‡ç¨‹
    
    <aside>
    ğŸ’¡ å°†å…·æœ‰ç›¸ä¼¼ç‰¹å¾å‘é‡çš„æ ·æœ¬æ”¾åœ¨åŒä¸€ç±»çš„æ–¹æ³•
    
    </aside>
    
    - æ„å»ºç‰¹å¾å‘é‡
        - å…·ä½“æ“ä½œæ­¥éª¤
            1. è¿”å›æŒ‰æœˆé‡æ’çš„å•ç‹¬æ—¶é—´åˆ—
                
                ```python
                import pandas as pd
                
                x = df_info.resample('M').count()
                x = x.drop(x.columns.values, axis=1)
                
                ```
                
                - ç›¸å…³è§£é‡Š
                    - `resample`æ–¹æ³•
                        
                        æ“ä½œ`Dataframe`å¯¹è±¡ï¼ŒæŒ‰æ—¶é—´åˆ—é‡é€‰é‡‡æ ·é¢‘ç‡ï¼Œé˜²æ­¢æ•°æ®ç¨ å¯†
                        
                        åœ¨è¿™é‡Œï¼Œ`M`Â ä»£è¡¨æŒ‰æœˆé‡æ–°é‡‡æ ·
                        
                        è¿”å›ä¸€ä¸ªÂ `Resampler`Â å¯¹è±¡
                        
                    - `count`æ–¹æ³•
                        
                        æ“ä½œ`Resampler`å¯¹è±¡ï¼Œè¿”å›ä¸€ä¸ª`Dataframe`å¯¹è±¡ï¼Œå¤§è‡´ä¸ºå¦‚ä¸‹æ ¼å¼
                        
                        | Date | Count |
                        | --- | --- |
                        | 2001-05-31 | 2 |
                        | 2001-06-30 | 3 |
                        | 2001-07-31 | 4 |
                        | 2001-08-30 | 1 |
                    - `drop`æ–¹æ³•
                        
                        æ“ä½œ`Dataframe`Â å¯¹è±¡
                        
                        - `labels`ï¼š`List`ç±»å‹ï¼ŒæŒ‡å®šåˆ é™¤çš„è¡Œã€åˆ—å
                        - `axis`ï¼šé»˜è®¤ä¸º`0`ï¼Œåˆ é™¤è¡Œï¼Œæ›´æ”¹ä¸º`1`æ—¶æŒ‡å®šåˆ é™¤åˆ—
                        - `index`ï¼šæŒ‡å®šåˆ é™¤çš„è¡Œç´¢å¼•
                        - `columns`ï¼šæŒ‡å®šåˆ é™¤çš„åˆ—ç´¢å¼•
                        - `inplace`ï¼šé»˜è®¤ä¸º`False`ï¼Œåˆ é™¤ä¸ä¼šæ”¹å˜åŸæ•°æ®ï¼Œè¿”å›`Dataframe`ï¼Œæ›´æ”¹ä¸º`True`ï¼Œç›´æ¥åœ¨åŸ`Dataframe`ä¸Šåˆ é™¤ï¼Œæ— è¿”å›å€¼
            2. å–å‡ºæ”¯ä»˜æ¬¡æ•°ç¬¬ä¸€å¤šï¼Œç¬¬äºŒå¤šçš„é¡¾å®¢IDå€¼
                
                ```
                i_rank = 1
                j_rank = 2
                
                i_id = df_info['é¡§å®¢ID'].value_counts().index[i_rank]
                j_id = df_info['é¡§å®¢ID'].value_counts().index[j_rank]
                
                ```
                
            3. å–å‡ºæ‰€æœ‰å¯¹åº”é¡¾å®¢IDå€¼çš„è¡Œï¼Œåˆ¶ä½œä»¥è¯¥é¡¾å®¢æ¯æœˆä½¿ç”¨æ¬¡æ•°ä¸ºå€¼çš„è¡¨æ ¼
                
                ```
                x_i = df_info[df_info['é¡§å®¢ID']==i_id].resample('M').count()
                x_j = df_info[df_info['é¡§å®¢ID']==j_id].resample('M').count()
                
                ```
                
            4. å¤„ç†ç¼ºå¤±å€¼
                
                ```
                x_i = pd.concat([x_0, x_i], axis=1).fillna(0)
                x_j = pd.concat([x_0, x_j], axis=1).fillna(0)
                
                ```
                
            5. è®¡ç®—ç›¸ä¼¼åº¦
                
                <aside> ğŸ’¡ ä»¥é¡¾å®¢æ¯æœˆä½¿ç”¨æ¬¡æ•°ä¸ºæ¯ç»´åº¦å€¼çš„ç‰¹å¾å‘é‡
                
                </aside>
                
                ```
                sig_x = x_i.iloc[;,0].values
                
                ```
                
                ```
                dx = x_i.iloc[;,0].values-x_j.iloc[:,0].values # ä¸¤ç‰¹å¾å‘é‡ä¹‹å·®
                n = np.linalg.norm(dx) # å·®å‘é‡é•¿åº¦ï¼ˆèŒƒæ•°ï¼‰
                sim = n/len(x_i) # é•¿åº¦æ ‡å‡†åŒ–åˆ°[0, 1]åŒºé—´
                
                ```
                
                - ç›¸å…³è§£é‡Š
                    
                    åœ¨`numpy`ä¸­ï¼Œ`pandas`çš„å•åˆ—`Dataframe`Â è¢«çœ‹ä½œé«˜ç»´å‘é‡ï¼Œè¿›è¡Œå‘é‡åŠ å‡
                    
                    è®¡ç®—ç‰¹å¾å‘é‡çš„è·ç¦»ï¼Œå¾—åˆ°ç›¸ä¼¼åº¦ï¼Œæ ‡å‡†åŒ–è¶Šæ¥è¿‘0ï¼Œä¸¤ç»„æ•°æ®ç›¸ä¼¼ç¨‹åº¦è¶Šé«˜
                    
            6. æŒ‰ç…§å¦‚ä¸Šæ–¹æ³•ï¼Œè®¡ç®—æ”¯ä»˜æ¬¡æ•°å‰ä¸€ç™¾åçš„é¡¾å®¢ç‰¹å¾å‘é‡
                
                <aside> ğŸ’¡ é€šè¿‡ä¸Šè¿°å¯¹ç›¸ä¼¼åº¦çš„è®¡ç®—ï¼ŒåŸºæœ¬ç¡®è®¤äº†å¯¹äºå¤§å®¢æˆ·è€Œè¨€ï¼Œæ­¤ç§é€‰å–æ–¹å¼å¾—åˆ°çš„ç‰¹å¾å‘é‡ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œæ¨ç†å‡ºå¤§å®¢æˆ·ä¸€èˆ¬ç¬¦åˆè¿™ç§è¡Œä¸ºé€»è¾‘
                
                </aside>
                
                ```
                list_vector = []
                total_num = 100
                for i_rank in range(total_num):
                    # ç¯©é¸å‡ºé¡§å®¢ID
                    i_id = df_info['é¡§å®¢ID'].value_counts().index[i_rank]
                    # å°‡æ¯æœˆä½¿ç”¨æ¬¡æ•¸è¨­å®šç‚ºç‰¹å¾µå€¼
                    x_i = df_info[df_info['é¡§å®¢ID']==i_id].resample('M').count()
                    # å‡ºç¾ç¼ºå¤±å€¼çš„è™•ç†æ–¹å¼
                    x_i = pd.concat([x_0, x_i], axis=1).fillna(0)
                    # æ–°å¢ç‚ºç‰¹å¾µå‘é‡
                    list_vector.append(x_i.iloc[:,0].values.tolist())
                
                ```
                
    - å¯è§†åŒ–ç‰¹å¾å‘é‡ï¼ˆPCAï¼‰
        
        <aside>
        ğŸ’¡ PCAå°†åˆ†å¸ƒåœ¨é«˜ç»´ç©ºé—´çš„ç‰¹å¾å‘é‡é™ç»´ï¼ŒæŠ•å½±åˆ°ä½ç»´ï¼ˆäºŒç»´ï¼‰è§‚å¯Ÿ
        
        </aside>
        
        - å…·ä½“æ“ä½œæ­¥éª¤
            1. è¿›è¡ŒPCAé™ç»´è¿‡ç¨‹
                
                ```python
                from sklearn.decomposition import PCA
                import numpy as np
                import matplotlib.pyplot as plt
                # è½‰æ›ç‰¹å¾µå‘é‡
                features = np.array(list_vector)
                # åŸ·è¡Œä¸»æˆåˆ†åˆ†æ
                pca = PCA()
                pca.fit(features)
                # å°‡ç‰¹å¾µå‘é‡è½‰æ›æˆä¸»æˆåˆ†
                transformed = pca.fit_transform(features)
                # å¯è¦–åŒ–
                for i in range(len(transformed)):
                    plt.scatter(transformed[i,0],transformed[i,1],color="k")
                    plt.text(transformed[i,0],transformed[i,1],str(i))
                plt.show()
                ```
                
                <aside>
                ğŸ’¡ åˆ†æåˆ†å¸ƒç‰¹å¾ï¼Œä¸€èˆ¬è€Œè¨€åˆ†å¸ƒè¾ƒä¸ºç´§å¯†çš„æ ·æœ¬ç‚¹ï¼Œè¡Œä¸ºæ¨¡å¼è¾ƒä¸ºç›¸ä¼¼
                
                </aside>
                
            2. å°†æƒ³è¦å…·ä½“åˆ†æçš„æ ·æœ¬é¡ºä½å–å‡ºï¼Œè§‚å¯Ÿæ—¥æœŸæŠ˜çº¿å›¾ï¼Œåˆ†ææ˜¯å¦å¦‚é¢„æœŸ
                
                ```python
                import pandas as pd
                # ç¯©é¸å‡ºindex
                x_0 = df_info.resample('M').count()
                x_0 = x_0.drop(x_0.columns.values,axis=1)
                
                # å…¶ä¸­22ï¼Œ25ï¼Œ42å·é¡¾å®¢åˆ†å¸ƒè¾ƒè¿‘ï¼Œè®¾å®šé¡ºä½
                list_rank = [22,25,42]
                x = []
                for i_rank in list_rank:
                    # ç¯©é¸å‡ºé¡§å®¢ID
                    i_id = df_info['é¡§å®¢ID'].value_counts().index[i_rank]
                    # å°‡æ¯æœˆä½¿ç”¨æ¬¡æ•¸è¨­å®šç‚ºç‰¹å¾µå€¼
                    x_i = df_info[df_info['é¡§å®¢ID']==i_id].resample('M').count()
                    # å‡ºç¾ç¼ºå¤±å€¼çš„è™•ç†æ–¹å¼
                    x_i = pd.concat([x_0, x_i], axis=1).fillna(0)
                    # ç¹ªè£½åœ–è¡¨
                    plt.plot(x_i)
                    plt.xticks(rotation=60)
                plt.show()
                ```
                
        - æ•°å­¦åŸç†åˆ†æ
            - PCAé™ç»´
                
                é™ç»´çš„æœ¬è´¨æ˜¯å¯¹$n$ä¸ªé«˜ç»´å‘é‡åšå¯¹äº$d$ä¸ªåŸºå‘é‡çš„æŠ•å½±ï¼š
                
      $$A=\left(a_1,a_2\cdots a_n\right)\xrightarrow[\left(p_1,p_2\cdots p_d\right)]{Remap}B=\left(b_1,b_2\cdots b_n\right)$$                
                è€ŒæŠ•å½±å¯ä»¥è¡¨ç¤ºä¸ºç‚¹ç§¯ï¼Œå…¶ä¸­å¯¹äºåŸºå‘é‡ï¼Œå¦‚æœå…¶ä¸ºå•ä½å‘é‡ï¼Œé‚£ä¹ˆç‚¹ç§¯çš„å€¼å³ä¸ºæŠ•å½±çš„é•¿åº¦ï¼Œæ•…è¿›è¡Œ $\vec{v} \cdot \vec{n}=Scal_nv$ï¼š
                
      $$\left(\begin{array}{c}p_{1} \\ p_{2} \\ \vdots \\ p_{d}\end{array}\right)\left(a_{1} , a_2\cdots a_{n}\right)=\left(\begin{array}{cccc}p_{1} a_{1} & p_{1} a_{2} & \cdots & p_{1} a_{n} \\ p_{2} a_{1} & p_{2} a_{2} & \cdots & p_{2} a_{n} \\ \vdots & \vdots & \ddots & \vdots \\ p_{d} a_{1} & p_{d} a_{2} & \cdots & p_{d} a_{n}\end{array}\right)$$                
                å…¶ä¸­ï¼Œ$p_d$ä¸º$d$ä¸ªåŸºå‘é‡ï¼Œ$a_n$ä¸º$n$ä¸ªåŸå‘é‡ï¼Œ$b_n$ä¸ºæ˜ å°„ä¹‹åçš„$n$ä¸ªå‘é‡
                
            - æ•°æ®çš„å‘é‡åŒ–å»ºæ¨¡
                
                æˆ‘ä»¬æœ‰å¤šä¸ªç”¨æˆ·çš„æ¯æœˆæ”¯ä»˜æ•°æ®ï¼Œé€²è¡Œå»ºæ¨¡ã€‚
                
                $\vec a_i = (x_i, y_i, z_i\cdots)$ç‚ºå–®å€‹ç”¨æˆ¶çš„æ¯æœˆæ”¯ä»˜æ•¸æ“šï¼š
                
      $$\left( \begin{array}{c}x_{1} \\ x_{2} \\ \vdots \\ x_{n}\end{array}\right)ï¼Œ\left( \begin{array}{c}y_{1} \\ y_{2} \\ \vdots \\ y_{n}\end{array}\right)ï¼Œ\left( \begin{array}{c}z_{1} \\ z_{2} \\ \vdots \\ z_{n}\end{array}\right)\cdots$$                
                æˆ‘ä»¬å°†$\vec{x},\ \vec{y},\ \vec{z} \cdots$ä½œä¸ºç»´åº¦è½´ï¼Œå¾—åˆ°ç‰¹å¾å‘é‡$\vec a_i = (x_i, y_i, z_i\cdots)$
                
            - åŸºå‘é‡çš„é€‰æ‹©
                - æœ€å¤§å¯åˆ†æ€§
                    
                    æˆ‘ä»¬å¸Œæœ›æŠ•å½±åçš„å‘é‡å°½å¯èƒ½åˆ†æ•£ï¼Œç”±äºçº¿æ€§ç›¸å…³æ€§ï¼Œè¶Šåˆ†æ•£çš„å‘é‡åŒ…å«çš„ä¿¡æ¯åˆ™è¶Šå¤šï¼Œå…¶ä¿¡æ¯ç†µä¹Ÿå°±è¶Šå¤§ï¼Œå¯åˆ†æ€§ä¹Ÿå°±è¶Šå¤§ã€‚
                    
                - æ–¹å·®
                    
                    æ ¹æ®å¦‚ä¸Šçš„è®ºè¿°ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç»„åŸºå‘é‡ï¼Œä½¿å¾—æ˜ å°„åçš„å‘é‡åŒ…å«çš„ä¿¡æ¯$x_i$çš„æ–¹å·®æœ€å¤§ï¼Œä¹Ÿå³ä¸º$x_i$ï¼ˆå…³äºåŸç‚¹ï¼‰çš„åˆ†å¸ƒè¶Šåˆ†æ•£ã€‚
                    
                    æ³¨æ„ï¼Œæ–¹å·®æ˜¯ä¸€ç»´ç‰¹å¾çš„æ€§è´¨ã€‚é’ˆå¯¹ç»„æˆç»´åº¦çš„å„ä¸ªåŸºå‘é‡è€Œè¨€ï¼Œå¯¹è¯¥åŸºå‘é‡ä¸Šä¸åŒæ ·æœ¬çš„æŠ•å½±æ¥è¿›è¡Œè®¡ç®—ï¼Œè¿›è€Œå¾—åˆ°å„ä¸ªåŸºå‘é‡ä¸Šæ•°æ®çš„æ–¹å·®ã€‚
                    
                    å¯¹äºè¿™ä¸ªæ¡ˆä¾‹ï¼ŒæŸç”¨æˆ·çš„æ‰€æœ‰æœˆä»½æ”¯ä»˜æ¬¡æ•°è¡¨ç¤ºä¸ºï¼š
                    
      $$\vec{x}=\left( \begin{array}{c}x_{1} \\ x_{2} \\ \vdots \\ x_{n}\end{array}\right)$$                    
                    å¯¹äºæ¯ä¸€ä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„æ–¹å·®å€¼ï¼Œå¯¹äº
                    
                    æˆ‘ä»¬æœ‰ $Base =\left( \vec{x},\vec{y},\vec{z}\cdots\right)$ï¼Œé‚£ä¹ˆ$\vec{x}$çš„æ–¹å·®å¯è¡¨ç¤ºä¸ºå¦‚ä¸‹å½¢å¼ï¼š
                    
      $$Var(\vec{x})=\frac{1}{n-1} \sum_{i=1}^{n} x_{i}^{2}$$                    
                - åæ–¹å·®
                    
                    é™¤äº†æ•°æ®æœ¬èº«ç¦»æ•£ç¨‹åº¦å¤§ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ•°æ®ä¹‹é—´ä¸¤ä¸¤æ— å…³ï¼Œä¸ºäº†è¡¨ç¤ºå°½å¯èƒ½å¤šçš„ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦å‘é‡çš„å„ä¸ªç»´åº¦å€¼ä¹‹é—´ä¿æŒçº¿æ€§æ— å…³ï¼Œå› æ­¤æ±‚è§£å„ä¸ªç»´åº¦ä¹‹é—´ä¸¤ä¸¤çš„åæ–¹å·®ï¼Œä½¿å…¶å€¼å‡ä¸º0ã€‚
                    
                    æ³¨æ„ï¼Œåæ–¹å·®æè¿°çš„æ˜¯ä¸¤ä¸ªç»´åº¦ç‰¹å¾ä¹‹é—´çš„æ— å…³æ€§ï¼Œæˆ‘ä»¬è®¡ç®—ä¸¤ä¸ªåŸºå‘é‡ä¸Šä¸åŒæ ·æœ¬çš„æŠ•å½±ï¼Œå¾—åˆ°è¿™ä¸¤ä¸ªåŸºå‘é‡ä¸Šæ•°æ®çš„åæ–¹å·®ã€‚
                    
                    å¯¹äºè¿™ä¸ªæ¡ˆä¾‹ï¼Œä¸¤ä¸ªç”¨æˆ·çš„æ‰€æœ‰æœˆä»½æ”¯ä»˜æ¬¡æ•°è¡¨ç¤ºä¸ºï¼š
                    
      $$\vec{x}=\left( \begin{array}{c}x_{1} \\ x_{2} \\ \vdots \\ x_{n}\end{array}\right)ï¼Œ\vec{y}=\left( \begin{array}{c}y_{1} \\ y_{2} \\ \vdots \\ y_{n}\end{array}\right)$$                    
                    å¯¹äºä»»æ„ä¸¤ä¸ªåŸºå‘é‡ä¸Šçš„æŠ•å½±æ•°æ®ï¼Œæˆ‘ä»¬æœ‰åæ–¹å·®ï¼š
                    
      $$Cov(\vec{x}, \vec{y})=\frac{1}{n-1}\sum_{i=1}^{n} x_i y_i$$                    
                - åæ–¹å·®çŸ©é˜µ
                    
                    æˆ‘ä»¬å°†$n$ä¸ªç»´åº¦çš„æ•°æ®åŒæ—¶è¿›è¡Œè®¡ç®—
                    
                    é¦–å…ˆï¼Œ$X=(\vec{x}, \vec{y}, \vec{z}\cdots)^T$ï¼Œä¸ºå¾…é™ç»´çš„åŸºå‘é‡æ–¹å‘æŠ•å½±æ•°æ®
                    
      $$X = \left(\begin{array}{cccc}x_{1} & x_{2} & \cdots & x_{n} \\ y_{1} & y_{2} & & y_{n} \\ \vdots & \vdots & \ddots & \vdots \\ w_{1} & w_{2} & \cdots & w_{n}\end{array}\right)$$                    
      $$\frac{1}{n} X X^{T}=\left(\begin{array}{cccc}\frac{1}{n} \sum_{i=1}^{n} x_i^{2} & \frac{1}{n} \sum_{i=1}^{n} x_i y_i & \cdots & \frac{1}{n} \sum_{i=1}^{n} x_i w_i \\ \\ \frac{1}{n} \sum_{i=1}^{n} y_i x_i & \frac{1}{n} \sum_{i=1}^{r} y_i^{2} & \cdots & \frac{1}{n} \sum_{i=1}^{n} y_i w_i \\ \vdots & \vdots & \ddots & \vdots \\ \frac{1}{n} \sum_{i=1}^{n} w_i x_i & \frac{1}{n} \sum_{i=1}^{n} w_i y_i & \cdots &\frac{1}{n} \sum_{i=1}^{n} w_i^2\end{array}\right)$$                    
      $$\operatorname{Cov}(\vec{x}, \vec{y} \cdots \vec{w})=\left(\begin{array}{cccc}\operatorname{Var}(\vec{x}) & \operatorname{Cov}(\vec{y} \vec{x}) & \cdots & \operatorname{Cov}(\vec{w} \vec{x}) \\ \\ \operatorname{Cov}(\vec{x} \vec{y}) & \operatorname{Var}(\vec{y}) & \cdots & \operatorname{Cov}(\vec{w} \vec{y}) \\ \vdots & \vdots & \ddots & \vdots \\ \operatorname{Cov}(\vec{x} \vec{w}) & \operatorname{Cov}\left(\vec{y} \vec{w}\right) & \cdots & \operatorname{Var}(\vec{w})\end{array}\right)$$                    
            - çŸ©é˜µå¯¹è§’åŒ–
                
                æ ¹æ®ä¼˜åŒ–çš„æ¡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦$\operatorname{Cov}(\vec{x}, \vec{y} \cdots \vec{w})$çš„å¯¹è§’å–æœ€å¤§å€¼ï¼Œå…¶ä½™å…ƒç´ å‡ä¸º0
                
      $$\begin{aligned} \operatorname{Cov}_{y} &=\frac{1}{n} Y Y^{\top} \\ &=\frac{1}{n}(P X)(P X)^{\top} \\ &=P\left(\frac{1}{n} XX^{\top}\right) P^{\top} \\ &=P \operatorname{Cov}_{x} P^{\top} \end{aligned}$$                
                å…¶ä¸­ï¼Œ$Y$ä¸º$X$åœ¨åŸºå‘é‡$P$æ–¹å‘ä¸Šçš„é‡æ˜ å°„ï¼Œæ¢è®¨$X$ä¸$Y$çš„åæ–¹å·®çŸ©é˜µå…³ç³»
                
                æœ€ç»ˆï¼Œé—®é¢˜å˜ä¸ºäº†å¯»æ‰¾ä¸€ä¸ª$P$ï¼Œä½¿å¾—$P \operatorname{Cov}_{x} P^{\top}$ä¸ºå¯¹è§’çŸ©é˜µã€‚
                
                ç”±äº${Cov}_{y}$*ä¸${Cov}_{x}$*åˆ†åˆ«ä¸ºå¯¹ç§°çŸ©é˜µï¼Œå‡å¯è¡¨ç¤ºä¸º$Cov = (\lambda_1 \vec{e_1}, \lambda_2 \vec{e_2}, \cdots)$
                
                å…¶ä¸­$E=(\vec{e_1},\vec{e_2},\cdots)$ï¼Œä¸ºå•ä½æ­£äº¤ç‰¹å¾å‘é‡ï¼ˆEigon Vectorï¼‰çš„è¡ŒçŸ©é˜µ
                
                å…¶ä¸­$\Lambda = \left(\begin{array}{llll}\lambda_{1} & & & \\ & \lambda_{1} & & \\ & & \ddots & \\ & & & \lambda_{n}\end{array}\right)$ï¼Œä¸ºç‰¹å¾å€¼ï¼ˆEigon Valueï¼‰çš„å¯¹è§’çŸ©é˜µ
                
                ç”±äº$P \operatorname{Cov}_{x} P^{\top} = Cov_y$ä¸ºå¯¹ç§°çŸ©é˜µï¼Œæ•…æ¯ä¸€åˆ—$A$éƒ½æœ‰$\lambda_k\vec{e_k}=A\vec{e_k}$
                
                æœ€ç»ˆï¼Œæˆ‘ä»¬å¯ä»¥æ„é€ å‡º$P \operatorname{Cov}{x} P^{\top} = Cov_y=\Lambda=E\operatorname{Cov}{x}E^T$
                
                å› æ­¤$P = E$ï¼Œæœ€ç»ˆï¼Œæˆ‘ä»¬åªéœ€è¦æ‰¾å‡º$Cov_y$çš„ç‰¹å¾å‘é‡çŸ©é˜µ$E$ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†åŸºå‘é‡çŸ©é˜µ$P$ã€‚
                
        - å‚è€ƒé“¾æ¥
            
            [ã€æœºå™¨å­¦ä¹ ã€‘é™ç»´--PCAï¼ˆéå¸¸è¯¦ç»†ï¼‰](https://zhuanlan.zhihu.com/p/77151308)
            
    - é›†ç¾¤åˆ†æï¼ˆK-Meanï¼‰
        
        <aside>
        ğŸ’¡ é›†ç¾¤åˆ†æå¯ä»¥åˆ¤æ–­å¤§å®¢æˆ·è¡Œä¸ºæ¨¡å¼çš„ç‰¹ç‚¹
        
        </aside>
        
        - å…·ä½“æ“ä½œæ­¥éª¤
            
            ```python
            from sklearn.cluster import KMeans
            # è¨­å®šé›†ç¾¤æ•¸
            num_of_cluster = 4
            # æŒ‡æ´¾é›†ç¾¤
            model = KMeans(n_clusters=num_of_cluster, random_state=0)
            model.fit(features)
            pred_class = model.labels_
            print(pred_class)
            ```
            
        - æ•°å­¦åŸç†åˆ†æ
            1. éšæœºé›†ç¾¤ä¸º$n$ä¸ªï¼Œ$A=(a,b,c\cdots)ï¼ŒBï¼ŒC\cdots$
            2. è®¡ç®—å„ä¸ªé›†ç¾¤çš„æ ·æœ¬å‡å€¼
                
      $$\bar{A}=\frac{1}{n}\sum_{i=1}^{n}A_i,\ \bar{B}=\frac{1}{n}\sum_{i=1}^{n}B_i,\cdots$$                
            3. é‡æ–°è®¡ç®—å„æ ·æœ¬ä¸æ ·æœ¬å‡å€¼çš„è·ç¦»ï¼Œå°†æ ·æœ¬é‡æ–°é›†ç¾¤åˆ°è¾ƒè¿‘çš„é›†ç¾¤ä¸­
                
                $\Omega=(a,b,c,\cdots,m,n)$ï¼Œä»¥æ ·æœ¬$a$ä¸ºä¾‹ï¼Œ$L_a=(a-\bar{A}, a-\bar{B},\cdots)$
                
                äºæ˜¯ï¼Œæ ·æœ¬$a$è¢«é‡æ–°å½’ç±»åˆ°$X$ä¹‹ä¸­ï¼Œ$a-\bar{X}=min(L_a)$
                
            4. é‡å¤å½’ç±»ï¼Œç›´åˆ°å½’ç±»ç»“æœä¸å†å‘ç”Ÿå˜åŠ¨
        - å‚è€ƒé“¾æ¥
            
            [ã€æœºå™¨å­¦ä¹ ã€‘K-meansï¼ˆéå¸¸è¯¦ç»†ï¼‰](https://zhuanlan.zhihu.com/p/78798251)
            
- åˆ†ç±»è¿‡ç¨‹
    - é€»è¾‘æ–¯è’‚å›å½’
        
        <aside>
        ğŸ’¡ é€»è¾‘æ–¯è’‚å›å½’æ˜¯çº¿æ€§å›å½’ä¸é€»è¾‘æ–¯è’‚å‡½æ•°çš„å åŠ æ¨¡å‹
        
        </aside>
        
        - æ•°å­¦åŸç†åˆ†æ
            
            çº¿æ€§å›å½’æ˜¯åˆ©ç”¨ä¸€æ¬¡å‡½æ•°æ‹Ÿåˆå˜é‡å…³ç³»çš„å›å½’è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹å…¶åµŒå¥—é€»è¾‘æ–¯è’‚å‡½æ•°ï¼Œå°†å›å½’è¿‡ç¨‹å˜ä¸ºåˆ†ç±»è¿‡ç¨‹ï¼š
            
      $$\text{logi}(x)=\sigma(\text{reg}(x))=\frac{1}{1+e^{-(m\cdot x + b)}}$$            
            å‡å®šæ•°æ®ç”±äºŒç»´åæ ‡ $(x_1, x_2)$ ç»™å‡ºï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥è§£å†³äºŒåˆ†ç±»é—®é¢˜ï¼š
            
      $$z=w_0+w_1x_1+w_2x_2$$            
            å…¶ä¸­ï¼Œ$z$ ä»£è¡¨äºŒç»´å¹³é¢ä¸­çš„å†³ç­–åˆ†ç•Œçº¿ï¼Œåœ¨ä¸€èˆ¬çš„å›å½’è¿‡ç¨‹ä¸­ï¼Œå¦‚æœ $h_w(x) = w_1x_1+w_2x_2+b > 0$ï¼Œé‚£ä¹ˆå…¶ä¸ºç”²ç±»ï¼Œåä¹‹ã€‚ä½†å¦‚æœæˆ‘ä»¬ç›´æ¥é‡å®š $z$ å¤§å°ï¼Œé‡‡ç”¨é˜¶æ¢¯å‡½æ•°æ¥åˆ†ç±»å¹¶ä¸å¯è¡Œï¼Œå› ä¸ºé˜¶æ¢¯å‡½æ•°ä¸å¯å¾®ï¼Œéš¾ä»¥é€šè¿‡æŸå¤±å‡½æ•°ä¼˜åŒ–åˆ†ç±»ã€‚å› æ­¤æˆ‘ä»¬ä½¿ç”¨è¿ç»­å¯å¾®çš„é€»è¾‘æ–¯è’‚å‡½æ•°å°† $h_w(x)$ æ˜ å°„åˆ°äº† $A=(0, 1)$ åŒºé—´å†…ï¼š
            
      $$p =  \frac{1}{1+e^{-(w^{T} x + b)}}$$            
            å¦‚æœ $p>0.5$ï¼Œåˆ™ä¸ºç”²ç±»ï¼Œåä¹‹ä¸ºä¹™ç±»ã€‚
            
            æˆ‘ä»¬é‡‡ç”¨æœ€å¤§ä¼¼ç„¶æ–¹æ³•ï¼Œä½¿å¾—æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡æœ€ç¬¦åˆç»™å®šæ•°æ®ï¼Œæˆ‘ä»¬è¿›è¡Œå¦‚ä¸‹å¤„ç†ï¼Œä½¿å¾—æ•°æ®å°½å¯èƒ½è¿œç¦»å†³ç­–åˆ†ç•Œçº¿ï¼Œå³ä»¥ä¸‹ä¸¤å€¼å°½å¯èƒ½å¤§ï¼š
            
      $$\begin{aligned} P(Y=1|x) &= p(x) \\  P(Y=0|x) &= 1- p(x) \end{aligned}$$            
            æˆ‘ä»¬æœ‰ä¼¼ç„¶å‡½æ•°å¦‚ä¸‹ï¼š
            
      $$\begin{aligned} L(w)=&\prod_i[p(x_{i})]^{y_{i}}[1-p(x_{i})]^{1-y_{i}} \\ =&\sum_i[y_{i}\ln p(x_{i})+(1-y_{i})\ln(1-p(x_{i}))] \\ =&\sum_i[y_{i}\ln\frac{p(x_{i})}{1-p(x_{i})}+\ln(1-p(x_{i}))]\end{aligned}$$            
            æˆ‘ä»¬å‘ç° $\ln\frac{p}{1-p}=w^{T} x + b=h_w(x)$ï¼Œå› æ­¤ï¼š
            
      $$L(w)=\sum[y_{i}(w \cdot x_{i}) - ln(1+e^{w \cdot x_{i}})]$$            
            æˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥è®¡ç®—è´Ÿå¹³å‡å¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼Œè½¬åŒ–ä¸ºæŸå¤±å‡½æ•°æ±‚æœ€å°å€¼ï¼š
            
      $$\begin{aligned} J(w)&=-\frac{1}{n}\ln L(w) \\&=  -\frac{1}{n}\sum_{i=1}^n[y_i\ln p(x_i)+(1-y_i)\ln(1-p(x_i)]\end{aligned}$$            
    - å†³ç­–æ ‘ï¼ˆID3ï¼ŒC4.5ï¼ŒCARTï¼‰
        
        <aside>
        ğŸ’¡ åˆ©ç”¨å†³ç­–æ ‘å¯ä»¥æ¨æ–­è¡Œä¸ºæ¨¡å¼çš„æˆå› 
        
        </aside>
        
        - å…·ä½“æ“ä½œæ­¥éª¤
            1. è®¾å®šç›®æ ‡å˜æ•°ï¼Œä¸ºç†æƒ³çš„åˆ†ç±»ç»“æœ
                
                ```python
                import numpy as np
                # è¨­å®šè¦åˆ†æçš„é¡åˆ¥
                target_class = 1
                # å»ºç«‹ç›®æ¨™è®Šæ•¸
                num = len(pred_class)
                data_o = np.zeros(num)
                for i in range(num):
                    if pred_class[i]==target_class:
                        data_o[i] = True
                    else:
                        data_o[i] = False
                print(data_o)
                
                ```
                
            2. è®¾å®šè¯´æ˜å˜æ•°ï¼ˆåŸå§‹æœªåˆ†ç±»æ•°æ®ï¼‰ï¼Œè¿›è¡Œå†³ç­–æ ‘åˆ†ç±»
                
                ```python
                # å»ºç«‹èªªæ˜è®Šæ•¸
                data_e = features
                print(data_e)
                ```
                
            3. ç”Ÿæˆå†³ç­–æ ‘ï¼Œä½¿è¯´æ˜å˜æ•°é€šè¿‡$n=2$æ¬¡å†³ç­–è¾¾åˆ°ç›®æ ‡å˜æ•°
                
                ```python
                from sklearn.tree import DecisionTreeClassifier
                from sklearn.tree import export_graphviz
                
                # å»ºç«‹æ±ºç­–æ¨¹çš„æ¨¡å‹
                clf = DecisionTreeClassifier(max_depth=2)
                clf = clf.fit(data_e, data_o)
                ```
                
            4. ç»˜åˆ¶å†³ç­–æ ‘ï¼Œè¾“å‡ºå†³ç­–çš„ç»“æœ
                
                ```python
                from dtreeviz.trees import dtreeviz
                
                # ç¯©é¸å‡ºindex
                x_0 = df_info.resample('M').count()
                x_0 = x_0.drop(x_0.columns.values,axis=1)
                time_index = x_0.index
                print(time_index)
                
                # ç¹ªè£½æ±ºç­–æ¨¹
                viz = dtreeviz(
                    clf,
                    data_e,
                    data_o,
                    target_name='Class',
                    feature_names=time_index,
                    class_names=['False','True'],
                )
                viz
                ```
                
            5. å¯è§†åŒ–åˆ†ç±»ç»“æœ
                
                ```python
                from sklearn.decomposition import PCA
                import numpy as np
                import matplotlib.pyplot as plt
                import matplotlib.patches as pat
                
                # é€²è¡Œåˆ†é¡
                pred_tree = clf.predict(data_e)
                
                # åŸ·è¡Œä¸»æˆåˆ†åˆ†æ
                pca = PCA()
                pca.fit(features)
                # å°‡ç‰¹å¾µå‘é‡è½‰æ›æˆä¸»æˆåˆ†
                transformed = pca.fit_transform(features)
                # å¯è¦–åŒ–
                plt.figure(figsize=(12, 8))
                plt.scatter(transformed[:,0],transformed[:,1],c=pred_class)
                for i in range(len(transformed)):
                    if pred_tree[i]==1:
                        if pred_class[i]==1:
                            temp_color = "k"
                            temp_lw = 1.0
                        else:
                            temp_color = "b"
                            temp_lw = 3.0
                        circle = pat.Circle(xy=(transformed[i,0],transformed[i,1]), 
                				radius=1.0, ec=temp_color ,fill=False, linewidth = temp_lw)
                        plt.axes().add_artist(circle)
                    else:
                        if pred_class[i]==1:
                            temp_color = "r"
                            temp_lw = 3.0
                            circle = pat.Circle(xy=(transformed[i,0],transformed[i,1]), 
                						radius=1.0, ec=temp_color ,fill=False, linewidth = temp_lw)
                            plt.axes().add_artist(circle)
                    text = str(i) + "(" + str(pred_class[i]) + ")"
                    plt.text(transformed[i,0],transformed[i,1],text)
                plt.show()
                %matplotlib inline
                ```
                
        - æ•°å­¦åŸç†åˆ†æ
            
            <aside>
            ğŸ’¡ æ„å»ºå†³ç­–æ ‘çš„æ ¸å¿ƒæ€æƒ³ä¸ºå¯»æ‰¾ä½¿ç†µä¸‹é™æœ€å¿«çš„ä¸€ç§å†³ç­–è¿‡ç¨‹ç»„åˆ
            
            </aside>
            
            - æ€»ä½“æ€è·¯
                - åˆå§‹åŒ–ç‰¹å¾é›†åˆï¼Œå‡†å¤‡å­¦ä¹ å·²åˆ†ç±»æ•°æ®é›†åˆï¼ˆå¸¦æœ‰ç‰¹å¾æ ‡ç­¾å’Œåˆ†ç±»ç»“æœæ ‡ç­¾ï¼‰
                - å¯¹æ¯ä¸ªå¾…é€‰ç‰¹å¾è®¡ç®—è¯¥ç®—æ³•çš„åˆ¤æ–­æŒ‡æ ‡ï¼Œæœ€å¤§çš„ç‰¹å¾ä½œä¸ºå½“å‰å†³ç­–èŠ‚ç‚¹
                - æ›´æ–°æ•°æ®é›†åˆï¼Œä»ç‰¹å¾é›†åˆä¸­åˆ’å»å·²ä½¿ç”¨çš„ç‰¹å¾
                - å‰ªæï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå‡å°è®¡ç®—é‡ï¼Œå¢å¤§åˆ†ç±»é€Ÿåº¦
            - ID3å†³ç­–æ ‘ç”Ÿæˆ
                - åˆ¤æ–­æŒ‡æ ‡
                    - ä¿¡æ¯ç†µ
                        
                        ID3å†³ç­–æ ‘æ˜¯ä¸€ç§ä»¥å†³ç­–è¿‡ç¨‹çš„ç†µå€¼ä½œä¸ºåˆ¤æ–­ä¾æ®è€Œç”Ÿæˆçš„å†³ç­–æ ‘ã€‚
                        
                        å‡è®¾å†³ç­–æ ‘ä¸ºäºŒå‰æ ‘ç»“æ„ï¼Œç»è¿‡$n$ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œæˆ‘ä»¬èƒ½å¾—åˆ°åˆ†ç±»åçš„ç»“æœã€‚
                        
                        é‚£ä¹ˆå¯¹äºæŸä¸ªå†³ç­–è¿‡ç¨‹ï¼ˆäºŒå‰æ ‘èŠ‚ç‚¹ï¼‰ï¼Œæˆ‘ä»¬æœ‰å†³ç­–ç»“æœï¼ˆåˆ†ç±»ç»“æœï¼‰ï¼š
                        
      $$R=\{x_1, x_2, x_3\cdots\}$$                        
                        å…³äºè¿™ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œç»“æœçš„å¹³å‡ä¿¡æ¯ç†µï¼ˆEtropyï¼‰å®šä¹‰ä¸º$E$ï¼š
                        
      $$E=-\sum_{R} P(x_i)\cdot log_2P(x_i)$$                        
                        å¦‚æœå†³ç­–æ ‘ä¸ºäºŒå‰æ ‘ï¼Œå¯¹æ¯ä¸€ä¸ªç‰¹å¾åªæœ‰ä¸¤ç§åˆ†ç±»ç»“æœ$R=\{x_1, x_2\}$
                        
                        å¯¹äºè¿™ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œæœ‰å¹³å‡ä¿¡æ¯ç†µï¼š
                        
      $$E=-P(x_1)\cdot log_2P(x_1)-P(x_2)\cdot log_2P(x_2)$$                        
      $$\left\{ \begin{array} {l} E_0=-\frac{1}{2}\cdot log_2\frac{1}{2}-\frac{1}{2}\cdot log_2\frac{1}{2}=1 & \\ E_1=-1\cdot0-0\cdot 1=0 \end{array} \right.$$                        
                        æˆ‘ä»¬å‘ç°è‰¯å¥½çš„å†³ç­–ï¼ˆä½éšæœºæ€§ï¼Œé«˜åº¦å¹²æ¶‰çš„åˆ†ç±»æ–¹å¼ï¼‰å¸¦æ¥çš„ç†µæ›´ä½ï¼Œä¸è‰¯çš„å†³ç­–ï¼ˆéšæœºè¾ƒé«˜ï¼Œ$p=0.5$ï¼‰å¸¦æ¥çš„ç†µæ›´é«˜ï¼Œè‰¯å¥½çš„å†³ç­–ä½¿ç³»ç»Ÿç†µå€¼å¿«é€Ÿä¸‹é™ã€‚
                        
                    - ä¿¡æ¯å¢ç›Š
                        
                        å®šä¹‰å†³ç­–è¿‡ç¨‹ä½¿ç†µä¸‹é™å¤§å°ä¸ºè¯¥å†³ç­–çš„ä¿¡æ¯å¢ç›Šï¼ˆInformation Gainï¼‰ä¸º$G$ï¼š
                        
      $$G_{p=n}=E_{p=n-1}-E_{p=n}$$                        
                        $E_{p=n-1}$ä¸ºç»éªŒç†µï¼Œåˆ†è£‚ä¹‹å‰çš„å†³ç­–é”™è¯¯ç‡ï¼š
                        
      $$E_{p=n-1}=H(D)=-\sum_{R} P(x_i)\cdot log_2P(x_i)$$                        
                        $E_{p=n}$ä¸ºæ¡ä»¶ç†µï¼Œé€‰å®šæŸä¸ªç‰¹å¾$A$ä½œä¸ºå†³ç­–è¿‡ç¨‹åçš„ç†µå€¼ï¼š
                        
      $$\begin{aligned}E_{p=n} = & H(D|A) \\= & \sum_{a\in R_A} H(D|A=a)\\= &  -\sum_{R} P(x_j)\cdot log_2P(x_j)\end{aligned}$$                        
                        å…¶ä¸­ï¼Œ$x_j$ä¸ºæœ¬æ¬¡å†³ç­–è¿‡ç¨‹çš„æŸä¸ªç»“æœï¼Œ$x_i$ä¸ºä¸Šæ¬¡å†³ç­–è¿‡ç¨‹çš„æŸä¸ªç»“æœã€‚
                        
                        åœ¨ID3ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬åˆ¤æ–­ä¿¡æ¯å¢ç›Š$G$çš„å¤§å°ï¼Œæ’å¸ƒå†³ç­–è¿‡ç¨‹ï¼Œåˆ¤æ–­çˆ¶èŠ‚ç‚¹å…³ç³»ï¼Œå¾—åˆ°ä¿¡æ¯ç†µä¸‹é™æœ€å¿«çš„å†³ç­–è¿‡ç¨‹ç»„åˆã€‚
                        
            - C4.5å†³ç­–æ ‘ç”Ÿæˆ
                - åˆ¤æ–­æŒ‡æ ‡
                    
                    <aside>
                    ğŸ’¡ è¿‡æ‹Ÿåˆä¸€èˆ¬è¡¨ç°ä¸ºè¿‡äºåå‘é‚£äº›å–å€¼è¾ƒå¤šçš„ç‰¹å¾è¿›è¡Œåˆ†ç±»
                    
                    </aside>
                    
                    C4.5å…‹æœäº†ID3çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼ˆOverfittingï¼‰ï¼Œåˆ©ç”¨ä¿¡æ¯å¢ç›Šç‡ï¼ˆInformation Gain Ratioï¼‰ä½œä¸ºåˆ¤æ–­ä¾æ®ç”Ÿæˆå†³ç­–æ ‘ï¼š
                    
      $$Gr=\frac{Gain(A)}{Split(A)}=\frac{G_{p=n}}{E_{p=n}}$$                    
                    å…¶ä¸­ï¼Œåˆ†æ¯ä»£è¡¨å†³ç­–è¿‡ç¨‹ç»“æœçš„ä¿¡æ¯ã€‚
                    
                    ä¿¡æ¯å¢ç›Šé™¤ä»¥ç»“æœä¿¡æ¯ï¼Œå¯ä»¥æœ‰æ•ˆéåˆ¶å…¶è¿‡åˆ†é€‰æ‹©ç»“æœç‰¹åˆ«å¤šçš„å†³ç­–è¿‡ç¨‹ã€‚
                    
                - å‰ªæç­–ç•¥
                    
                    <aside>
                    ğŸ’¡ ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆå¸¦æ¥çš„å½±å“ï¼ŒC4.5æ¨¡å‹å¼•å…¥äº†å‰ªæç­–ç•¥
                    
                    </aside>
                    
                    - é¢„å‰ªæ
                        1. åˆ†è£‚å‰æ ·æœ¬$d\in D$å‡å°äºæŸé¢„å…ˆè®¾å®šå¥½çš„é˜ˆå€¼$\alpha$ï¼Œä¸åˆ†è£‚
                        2. æ‰€æœ‰çš„ç‰¹å¾$a\in A$å‡å·²ç»åˆ†è£‚è¿‡ï¼Œä¸åˆ†è£‚
                        3. åˆ†è£‚åï¼Œåˆ†ç±»çš„å‡†ç¡®æ€§é™ä½ï¼Œä¸åˆ†è£‚
                    - åå‰ªæ
                        
                        ç”±ä½ä½åˆ°é«˜ä½é€’å½’ï¼Œå¯¹é™¤å¶å­èŠ‚ç‚¹ï¼ˆEnd Pointï¼‰ä»¥å¤–èŠ‚ç‚¹ï¼Œåˆ¤æ–­å…¶ä¸åˆ†è£‚æ˜¯å¦æ›´ä¼˜ï¼ˆç”¨ä¸€ä¸ªæœ€ä¼˜å¶å­èŠ‚ç‚¹ä»£æ›¿å­æ ‘ï¼‰ï¼Œä»¥æ ·æœ¬çš„é”™è¯¯åˆ†ç±»æ•°é‡ä¸ºä¾æ®ã€‚
                        
                        ![graph(1).png](%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%203aa5b757281d4f529f9103b0a4e7d243/graph(1).png)
                        
                        å…¶ä¸­ï¼Œ$C_n$ä»£è¡¨å†³ç­–ç‰¹å¾ï¼Œ$R_n$ä»£è¡¨å½’ç±»çš„ç»“æœï¼Œæ¯”å¦‚æœ€ç»ˆç»“æœæœ‰ä¸‰ç§ç±»åˆ«ï¼Œé‚£ä¹ˆ$R_n\in \{x_1,x_2,x_3\}$ã€‚
                        
            - CARTå†³ç­–æ ‘ç”Ÿæˆ
                - åˆ¤æ–­æŒ‡æ ‡
                    
                    <aside>
                    ğŸ’¡ åŸºå°¼ä¸çº¯åº¦é¿å…äº†ç†µçš„å¯¹æ•°è¿ç®—ï¼Œé€Ÿåº¦æå‡
                    
                    </aside>
                    
                    CARTåˆ©ç”¨åŸºå°¼ä¸çº¯åº¦ä½œä¸ºåˆ¤æ–­ä¾æ®ç”ŸæˆäºŒå‰å†³ç­–æ ‘ï¼š
                    
      $$Gini = \sum_{i=1}^{k}{}p_i\cdot(1-p_i)=1-\sum_{i=1}^{k}p_i^{2}$$                    
                    å…¶ä¸­ï¼Œ$p_i$ä¸ºå†³ç­–ç»“æœçš„å¯èƒ½æ€§ã€‚
                    
                    åŸºå°¼æŒ‡æ•°è¡¨ç¤ºäº†ä»è®­ç»ƒé›†ä¸­éšæœºæŠ½å–ä¸¤ä¸ªæ ·æœ¬ï¼Œç±»åˆ«ä¸ä¸€è‡´çš„æ¦‚ç‡ã€‚
                    
                    å½“ $p_i=p_j=\cdots=\frac{1}{k}$ æ—¶ï¼ŒåŸºå°¼ä¸çº¯åº¦æœ€å¤§ï¼Œæ ·æœ¬çº¯åº¦ä½ï¼Œç‰¹å¾è¾ƒå¥½ã€‚
                    
                    å½“ $p_i=1,p_j=p_k=\cdots=0$ æ—¶ï¼ŒåŸºå°¼ä¸çº¯åº¦æœ€å°ï¼Œæ ·æœ¬çº¯åº¦é«˜ã€‚
                    
                    ç‰¹åˆ«åœ°ï¼ŒåŸºå°¼ä¸çº¯åº¦è¿‘ä¼¼åœ°ä¸ºä¿¡æ¯ç†µçš„ä¸€é˜¶æ³°å‹’å±•å¼€ï¼š
                    
      $$E=-\sum_{k=1}^{K} p_{k} \ln p_{k}\approx \sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=Gini$$                    
                    CARDå†³ç­–æ ‘ç”Ÿæˆæ²¡æœ‰åœæ­¢æ¡ä»¶ï¼Œä¼šä¸€ç›´ç”Ÿé•¿ã€‚
                    
                - å‰ªæç­–ç•¥
                    
                    CARTç®—æ³•ä½¿ç”¨ä»£ä»·å¤æ‚åº¦å‰ªææ–¹æ³•ï¼š
                    
                    èŠ‚ç‚¹è¶Šå¤šï¼Œè¯¯å·®è¶Šå°ï¼Œä½†æœ‰çš„èŠ‚ç‚¹å¯¹è¯¯å·®å‡å°‘çš„è´¡çŒ®ç‡å¤§ï¼Œæœ‰çš„è´¡çŒ®å°ã€‚æˆ‘ä»¬æ‰¾å‡ºé‚£äº›ä½¿ç”¨è¾ƒå¤šå­èŠ‚ç‚¹ï¼Œä½†è´¡çŒ®å°çš„å­æ ‘ï¼ŒæŠŠå®ƒå‰ªè£æ‰ã€‚
                    
                    äºæ˜¯å°æ ‘å¤§è´¡çŒ®ä¿ç•™ï¼Œå¤§æ ‘å°è´¡çŒ®å‰ªæï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä¸€ç§åŒæ—¶è¡¡é‡ä¸€æ£µæ ‘å¯¹è¯¯å·®å‡å°è´¡çŒ®ä¸æ ‘çš„è§„æ¨¡çš„æ–¹æ³•ï¼š
                    
      $$C_\alpha(T)=C(T)+\alpha|T|$$                    
                    å…¶ä¸­ï¼Œ$C(T)$ä¸ºæ ‘$T$ä½¿åˆ†ç±»è¯¯å·®å‡å°çš„å€¼ï¼ˆåŸºå°¼æŒ‡æ•°ï¼‰ï¼Œ$|T|$ä¸ºæ ‘$T$çš„èŠ‚ç‚¹æ•°é‡ï¼Œ$\alpha$ä¸ºæƒè¡¡æ ‘çš„è§„æ¨¡ä¸è¯¯å·®å‡å°è´¡çŒ®çš„å‚æ•°ã€‚
                    
                    å…·ä½“è€Œè¨€ï¼Œå¯¹äºæ¯ä¸€ä¸ªå­æ ‘$T_t$è€Œè¨€ï¼Œå‰ªæä¹‹å‰éƒ½æœ‰ï¼š
                    
      $$C_\alpha(T_t)=C(T_t)+\alpha|T_t|$$                    
                    å…¶ä¸­ï¼Œ$t$ä»£è¡¨å­æ ‘$T_t$çš„æ ¹èŠ‚ç‚¹ï¼Œ$C(T_t)$ä¸ºæ ‘$T$ä½¿åˆ†ç±»è¯¯å·®å‡å°çš„å€¼ï¼ˆåŸºå°¼æŒ‡æ•°ï¼‰ã€‚
                    
                    è€Œå‰ªæä¹‹åéƒ½æœ‰ï¼š
                    
      $$C_\alpha(t)=C(t)+\alpha\cdot1$$                    
                    å› æ­¤ï¼Œæˆ‘ä»¬åœ¨å‰ªæé˜¶æ®µï¼Œé¦–å…ˆæœ‰CARTç®—æ³•ç”Ÿæˆçš„$T_0$ï¼Œæœ‰$\alpha=+\infty$ï¼Œå¯¹äº$T_0$çš„æ¯ä¸€ä¸ªå­èŠ‚ç‚¹$t$ï¼Œæˆ‘ä»¬éƒ½ï¼ˆç”±ä¸‹è€Œä¸Šåœ°ï¼‰è®¡ç®—æŒ‡æ ‡$g(t)$ï¼š
                    
      $$g(t) = \frac{C(t)-C(T_t)}{|T_t|-1}  \\$$                    
      $$\alpha=min(\alpha, g(t))$$                    
                    å…¶ä¸­ï¼Œ$T_t$ä¸ºä»¥$t$ä¸ºæ ¹èŠ‚ç‚¹çš„å­æ ‘ã€‚
                    
                    å…¶æ¬¡ï¼Œï¼ˆç”±ä¸Šè€Œä¸‹åœ°ï¼‰è®¡ç®—æ‰€æœ‰$t$èŠ‚ç‚¹çš„$g(t)$ï¼Œå¦‚æœ$g(t)=a$ï¼Œé‚£ä¹ˆ$t$å¯¹åº”çš„$T_t$ä¸º$T_0$çš„æœ€å·®å­æ ‘ï¼Œå°†$T_t$ä»$T_0$ä¸­å‰ªé™¤ã€‚$t$æˆä¸ºäº†å¶å­èŠ‚ç‚¹ï¼Œå°†å‰ªé™¤å‰$T_t$çš„æœ€å¤šçš„åˆ†ç±»ç»“æœä½œä¸ºå¶å­èŠ‚ç‚¹$t$çš„åˆ†ç±»ç»“æœï¼Œå¾—åˆ°å‰ªé™¤åçš„CARTç”Ÿæˆæ ‘$T_1$ã€‚
                    
                    æ¥ç€ï¼Œç”±$T_0$è¿›è¡Œäº†ä¸€æ¬¡å‰ªé™¤ï¼Œæˆ‘ä»¬å¾—åˆ°äº†$T_1$ï¼Œå¯¹$T_1$é‡å¤ä¸Šè¿°æ“ä½œï¼Œé€’å½’ç›´åˆ°æ ‘åªå‰©å•ä¸ªèŠ‚ç‚¹ã€‚æœ€ç»ˆæˆ‘ä»¬å¾—åˆ°äº†$\{T_0,T_1\cdots T_n\}$ï¼Œä½¿ç”¨ç”¨æ¥æµ‹è¯•çš„å¦ä¸€ä»½äººå·¥æ ‡è®°æ•°æ®é›†ï¼Œå¯¹$\{T_0,T_1\cdots T_n\}$å†…æ‰€æœ‰æ ‘é€ä¸€æµ‹è¯•åˆ†ç±»å‡†ç¡®åº¦ï¼Œé€‰æ‹©æœ€ä¼˜æ ‘$T_k$ã€‚
                    
        - å‚è€ƒé“¾æ¥
            
            [ã€æœºå™¨å­¦ä¹ ã€‘å†³ç­–æ ‘ï¼ˆä¸Šï¼‰--ID3ã€C4.5ã€CARTï¼ˆéå¸¸è¯¦ç»†ï¼‰](https://zhuanlan.zhihu.com/p/85731206)
            
            [CARTå†³ç­–æ ‘å‰ªæ--æœºå™¨å­¦ä¹ ](https://zhuanlan.zhihu.com/p/521202734)
            
    - éšæœºæ£®æ—ï¼ˆRandom Forestsï¼‰
        
        <aside>
        ğŸ’¡ å†³ç­–æ£®æ—å‡å°‘äº†æ•°æ®é€‰å–çš„ç‰¹å¼‚æ€§ï¼Œç‰¹å¾é€‰å–çš„ç‰¹å¼‚æ€§å¯¹åˆ†ç±»çš„å½±å“
        
        </aside>
        
        - å…·ä½“æ“ä½œæ­¥éª¤
            
            ç”Ÿæˆæ ·æœ¬çš„éšæœºæ£®æ—ï¼Œä¸å…¶å¯¹åº”çš„æ··æ·†çŸ©é˜µ
            
            ```python
            from sklearn.model_selection import train_test_split
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.metrics import confusion_matrix
            
            # å°‡è³‡æ–™é›†åˆ†å‰²æˆè¨“ç·´è³‡æ–™èˆ‡è©•ä¼°è³‡æ–™
            x_train, x_test, y_train, y_test = train_test_split(features,data_o)
            
            # åˆ©ç”¨è¨“ç·´è³‡æ–™å»ºç«‹æ¨¡å‹
            model = RandomForestClassifier(bootstrap=True, n_estimators=10, max_depth=None, random_state=1)
            clf = model.fit(x_train, y_train)
            
            # åˆ©ç”¨è©•ä¼°è³‡æ–™é€²è¡Œè©•ä¼°
            # è¨ˆç®—åˆ†æ•¸
            score = clf.score(x_test, y_test)
            print("åˆ†æ•¸:",score)
            
            # ç”¢ç”Ÿæ··æ·†çŸ©é™£
            pred_tree = clf.predict(x_test)
            cm = confusion_matrix(y_test, pred_tree)
            print("æ··æ·†çŸ©é™£")
            print(cm)
            ```
            
        - æ•°å­¦åŸç†åˆ†æ
            
            å°† $n$ ä¸ªæ ·æœ¬æœ‰æ”¾å›åœ°ä» $N$ ä¸ªæ ·æœ¬ä¸­æŠ½å‡ºï¼Œå°† $m$ ä¸ªç‰¹å¾ä» $M$ ä¸ªæ ·æœ¬ä¸­æŠ½å‡ºï¼Œä»¥ $n$ ä¸ªæ ·æœ¬ï¼Œ$m$ ä¸ªç‰¹å¾ç»„æˆä¸€æ£µå†³ç­–æ ‘ã€‚
            
            ![Web 1920 â€“ 1.png](%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%203aa5b757281d4f529f9103b0a4e7d243/Web_1920__1.png)
            
            é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œå¾—åˆ°æ•°æ£µå†³ç­–æ ‘ï¼Œç»„æˆå†³ç­–æ£®æ—ã€‚æœ€ç»ˆçš„åˆ†ç±»ç»“æœç”±æ•°æ£µå†³ç­–æ ‘çš„ç»“æœåŒæ—¶å†³å®šï¼Œæœ€ç»ˆæˆ‘ä»¬å¾—åˆ°æŠ•ç¥¨å†³å®šçš„åˆ†ç±»ç»“æœã€‚
            
        - å‚è€ƒé“¾æ¥
            
            [éšæœºæ£®æ—è¯¦è§£ï¼ˆä»å†³ç­–æ ‘ç†è§£éšæœºæ£®æ—ï¼‰](https://zhuanlan.zhihu.com/p/471494060)
            
    - æ”¯æ´å‘é‡æœºï¼ˆSVMï¼‰
        
        <aside>
        ğŸ’¡ æ”¯æ´å‘é‡æœºåˆ©ç”¨ç»´åº¦é¢å°†ç‰¹å¾å‘é‡åˆ‡æˆä¸¤éƒ¨åˆ†ï¼Œå®ç°äºŒåˆ†ç±»æ“ä½œ
        
        </aside>
        
        - å…·ä½“æ“ä½œæ­¥éª¤
            
            åˆ©ç”¨æ”¯æ´å‘é‡æœºè¿›è¡Œæ ·æœ¬äºŒåˆ†ç±»
            
            ```python
            from sklearn.model_selection import train_test_split
            from sklearn.svm import SVC
            from sklearn.metrics import confusion_matrix
            
            # å°‡è³‡æ–™é›†åˆ†å‰²æˆè¨“ç·´è³‡æ–™èˆ‡è©•ä¼°è³‡æ–™
            x_train, x_test, y_train, y_test = train_test_split(features,data_o)
            
            # åˆ©ç”¨è¨“ç·´è³‡æ–™å»ºç«‹æ¨¡å‹
            model = SVC(kernel='rbf')
            clf = model.fit(x_train, y_train)
            
            # åˆ©ç”¨è©•ä¼°è³‡æ–™é€²è¡Œè©•ä¼°
            # è¨ˆç®—åˆ†æ•¸
            score = clf.score(x_test, y_test)
            print("åˆ†æ•¸:",score)
            
            # ç”¢ç”Ÿæ··æ·†çŸ©é™£
            pred_tree = clf.predict(x_test)
            cm = confusion_matrix(y_test, pred_tree)
            print("æ··æ·†çŸ©é™£")
            print(cm)
            ```
            
        - æ•°å­¦åŸç†åˆ†æ
            
            åœ¨ç©ºé—´ä¸­æœ‰ $V=(\vec{x_1}, \vec{x_2}\cdots\vec{x_n})$ï¼Œåˆ©ç”¨ä¸€ï¼ˆè¶…ï¼‰å¹³é¢å°†å‘é‡åˆ‡åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œå®ç°äºŒåˆ†ç±»ï¼Œä¸¤ç±»ä¸­è·ç¦»è¶…å¹³é¢æœ€è¿‘çš„å‘é‡è¢«ç§°ä¸ºæ”¯æŒå‘é‡ã€‚
            
            - ä½ç»´çº¿æ€§å¯åˆ†çš„SVM
                
                å¯¹äºçº¿æ€§å¯åˆ†çš„æ•°æ®è€Œè¨€ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°æ— æ•°ä¸ªè¶…å¹³é¢ $X^T\cdot\vec{w}+b=0$ï¼Œå°†  $V$ åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œå…¶ä¸­ $X^T$ ä¸ºé¢å‘é‡ï¼Œ$\vec{w}$ ä¸ºå¹³é¢æ³•å‘é‡ï¼Œ$b$ ä¸ºæˆªè·ã€‚
                
                ![v2-197913c461c1953c30b804b4a7eddfcc_1440w.jpg](%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%203aa5b757281d4f529f9103b0a4e7d243/v2-197913c461c1953c30b804b4a7eddfcc_1440w.jpg)
                
                å›¾ä¸­è™šçº¿ç©¿è¿‡çš„å‘é‡ä¸ºæ”¯æŒå‘é‡ $\vec{x_s}$ï¼Œå…¶ç¬¦åˆ $\vec{x_s}\cdot\vec{w}+b=\pm 1$
                
                æ”¯æŒå‘é‡ä¸è¶…å¹³é¢çš„è·ç¦»ç§°ä¸ºé—´éš”ï¼ˆMarginï¼‰ï¼Œè®°ä¸º $\rho$ï¼š
                
      $$\rho=\frac{2}{\|\vec{w}\|}$$                
                å…¶ä¸­ï¼Œ$\|\vec{w}\|$ ä¸ºé«˜ç»´å‘é‡çš„æ¨¡é•¿ã€‚
                
                æˆ‘ä»¬åˆ©ç”¨é—´éš”å¤§å°åˆ¤æ–­è¶…å¹³é¢é€‰å–çš„ä¼˜åŠ£ã€‚é—´éš”è¶Šå¤§ï¼Œåˆ™åˆ†ç±»å®¹å¿åº¦è¶Šé«˜ï¼Œé—´éš”è¶Šå°ï¼Œè¶Šå®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚ç”±æ­¤çœ‹æ¥ï¼Œå¯¹äºè¶…å¹³é¢ $X^T\cdot\vec{w}+b=0$ï¼Œä¼˜åŒ–çš„æ‰‹æ®µä¸ºæ‰¾åˆ° $\rho$ çš„æœ€å¤§å€¼ï¼š
                
      $$max_{\vec{w}, b}(\rho)\iff min_{\vec{w}, b}(\|\vec{w}\|)\iff min_{\vec{w}, b}(\frac{1}{2}\cdot\|\vec{w}\|^2)=J(w)_{min}$$                
                å¯¹äºç»™å®šè¶…å¹³é¢ $\vec{x_s}\cdot\vec{w}+b=\pm 1$ ï¼Œå®šä¹‰è¶…å¹³é¢å…³äºæ ·æœ¬ç‚¹ $\left( x_i,y_i \right)$ çš„å‡ ä½•é—´éš”ï¼š
                
      $$\gamma _i=y_i\left( \frac{\vec{w}}{\lVert \vec{w} \rVert}\cdot \vec{x}_{i}+\frac{b}{\lVert \vec{w} \rVert} \right)$$                
                åœ¨æ‰€æœ‰æ ·æœ¬ç‚¹ $\left( x_i,y_i \right)_{ i=1,2,\cdots ,N}$  ä¸­ï¼Œå‡ ä½•é—´éš”æœ€å°å€¼ä¸ºï¼š
                
      $$\gamma_{min} =\underset{i=1,2,\cdots ,N}{\min}\gamma _i=\rho$$                
                é™¤æ”¯æŒå‘é‡å¤–ï¼Œæ‰€æœ‰å‘é‡å…³äºè¶…å¹³é¢çš„å‡ ä½•é—´éš”éƒ½å¤§äº $\gamma_{min}$ï¼š
                
      $$y_i\left( \frac{\vec{w}}{\lVert \vec{w} \rVert}\cdot \vec{x}_{i}+\frac{b}{\lVert \vec{w} \rVert} \right) \ge \gamma_{min}=\rho \ ,i=1,2,...,N$$                
                åŒ–ç®€å¾— $\rho=J(w)_{min}=\frac{1}{2}\cdot\|\vec{w}\|^2$ çš„çº¦æŸæ¡ä»¶ï¼š
                
      $$y_i\left( \frac{\vec{w}}{\lVert \vec{w} \rVert\cdot \rho}\cdot \vec{x}_{i}+\frac{b}{\lVert \vec{w} \rVert\cdot \rho} \right) \ge 1 \ ,i=1,2,...,N$$                
                è¿™é‡Œæ˜¯ä¸€ä¸ªå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œåˆ©ç”¨å¸¦æœ‰ $KKT$ æ¡ä»¶çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•æ±‚è§£ $\rho$ çš„æœ€å¤§å€¼ï¼Œæˆ‘ä»¬å°†å¤šä¸ªä¸ç­‰å¼çº¦æŸä¸‹çš„$J(w)_{min}$è½¬åŒ–ä¸ºæ— çº¦æŸçš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°ï¼š
                
      $$L(\vec{w},b,\lambda_i,p_i)=\frac{1}{2}\cdot\|\vec{w}\|^2-\sum_{i=1}^{N}\lambda_i (y_i\left(W\cdot \vec{x}_{i}+B\right)-1-{p_i}^2)$$                
                ç”±çº¦æŸæ¡ä»¶å¾—ï¼Œå¯è¡ŒåŸŸä¸º$A\cup B$ï¼š
                
                å…¶ä¸­ï¼Œ$\lambda_i$ ä¸ºæ¯ä¸ªçº¦æŸæ¡ä»¶çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼Œ$\lambda_i\ge0$ï¼Œ${p_i}^2$ å°†ä¸ç­‰å¼è°ƒå¹³ä¸ºç­‰å¼ï¼Œä¸ºäº†æ–¹ä¾¿è¡¨ç¤ºï¼Œæˆ‘ä»¬å†™ä½œ $W=\frac{\vec{w}}{\lVert \vec{w} \rVert\cdot \rho}$ï¼Œ$B=\frac{b}{\lVert \vec{w} \rVert\cdot \rho}$
                
                ç”±çº¦æŸæ¡ä»¶ï¼Œæ ·æœ¬ç‚¹ $(x_i,y_i)$ çš„å¯è¡ŒåŸŸä¸ºï¼š
                
      $$A=\{(x_i,y_i)\ | \ y_i\left( W\cdot \vec{x}_{i}+B \right) > 1\}$$                
      $$B=\{(x_i,y_i)\ | \ y_i\left( W\cdot \vec{x}_{i}+B \right) = 1\}$$                
                å¯¹ $L(\vec{w},b,\lambda,p_i)$ å·¦å³åˆ†åˆ«å¯¹ $\vec{w},b,\lambda,p_i$ æ±‚åå¯¼æ•°ï¼Œä½¿å…¶åˆ†åˆ«ç­‰äº$0$
                
                æˆ‘ä»¬å¾—åˆ°å¦‚ä¸‹å››ä¸ª $KKT$ æ¡ä»¶ï¼š
                
                ä¸ç­‰å¼çº¦æŸçš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°è§„å®šï¼Œå¦‚æœæ ·æœ¬ç‚¹ $(x_i,y_i)\in A$ï¼Œé‚£ä¹ˆ $\lambda_i=0$ï¼Œå¦‚æœæ ·æœ¬ç‚¹ $(x_i,y_i)\in B$ï¼Œé‚£ä¹ˆ $\lambda_i\neq0$ï¼Œå¦‚æœæ ·æœ¬ç‚¹è„±ç¦»å¯è¡ŒåŸŸï¼Œä¸åœ¨è®¨è®ºèŒƒå›´ã€‚
                
                1. $\vec{w}-\sum_{i=1}^{N}\lambda_i\cdot y_i \cdot x_i=0$
                2. $\sum_{i=1}^{N}\lambda_i\cdot y_i=0$
                3.  $y_i\left(W\cdot \vec{x}_{i}+B\right)-1-{p_i}^2=0$
                4. $2 \lambda_i  p_i=0$
                
                ç”±3ï¼Œ4å¾—åˆ°ï¼š$\lambda_i[y_i\left(W\cdot \vec{x}_{i}+B\right)-1]=0$
                
                å¦‚æœæ ·æœ¬ç‚¹ $(x_i,y_i)\in A$ï¼Œé‚£ä¹ˆ $\lambda_i=0$ å¿…ç„¶æˆç«‹ï¼Œå¦‚æœæ ·æœ¬ç‚¹$(x_i,y_i)\in B$ï¼Œé‚£ä¹ˆ$\lambda_i\neq0$ å¯ä»¥æˆç«‹ã€‚ç”±äº $\lambda_i$ ä¸ºä¸¤æ¢¯åº¦å‘é‡çš„æ­£å‘é•¿åº¦æ¯”ï¼Œå› æ­¤æœ€å$\lambda_i \geq 0$
                
                åˆ©ç”¨å¦‚ä¸Šå››ä¸ªåŸ $KKT$ æ¡ä»¶ï¼Œä»¥åŠä¸¤ä¸ªè¡ç”Ÿæ¡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥æ±‚è§£æœ€ä¼˜è¶…å¹³é¢ã€‚
                
            - æ ¸æŠ€å·§ï¼ˆä½ç»´çº¿æ€§ä¸å¯åˆ†çš„SVMï¼‰
                
                <aside>
                ğŸ’¡ å°†ä½ç»´ä¸æ˜“äºŒåˆ†ç±»æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ååˆ†ç±»æ—¶ï¼Œç®€åŒ–é«˜ç»´ç‚¹ç§¯è®¡ç®—æ–¹æ³•
                
                </aside>
                
                å½“å¯¹å¶é—®é¢˜ä¸­ $\vec{x}_{i}\cdot \vec{x}_{j}$ ä¸å¯è§£æ—¶ï¼Œæˆ‘ä»¬åˆ©ç”¨å‡ç»´å‡½æ•° $T(\vec{x})$ï¼Œå°† $\vec{x}$ æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ï¼Œå¹¶è®¡ç®— $T(\vec{x}_{i})\cdot T(\vec{x}_{j})=\sum_{m=1}^N x_{im}x_{jm}$
                
                ä¸ºäº†ç®€åŒ–ä»¥ä¸Šé«˜ç»´ç‚¹ç§¯ï¼Œæˆ‘ä»¬å°è¯•æ‰¾åˆ°æ ¸å‡½æ•° $T(\vec{x}_{i})\cdot T(\vec{x}_{j})=K(\vec{x}_{i}, \vec{x}_{j})$
                
                å¦‚æœæˆ‘ä»¬èƒ½æ‰¾åˆ°æ ¸å‡½æ•° $K(\vec{x}_{i}, \vec{x}_{j})$ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥ç›´æ¥è·³è¿‡å‡ç»´æ­¥éª¤ï¼Œç›´æ¥è®¡ç®—ä¸¤å‘é‡åœ¨é«˜ç»´çš„ç‚¹ç§¯ç»“æœï¼š
                
      $$K_{c,d}(\vec{x}_{i}, \vec{x}_{j})=(c+\vec{x}_{i}\cdot\vec{x}_{j})^d$$                
                å…¶ä¸­ï¼Œä¸åŒ $c,d$ çš„ç»„åˆèƒ½æ§åˆ¶è½¬åŒ–åçš„ç»´åº¦å’Œç©ºé—´ç›¸ä¼¼åº¦ï¼Œå½±å“è¶…å¹³é¢çš„é€‰å–ã€‚
                
                æ›´é«˜çº§åœ°ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å¯»æ‰¾ $\vec{x}_{i}\cdot \vec{x}_{j}$ åœ¨æ— é™é«˜ç»´åº¦ä¸Šçš„ç‚¹ç§¯ç»“æœï¼Œæˆ‘ä»¬ä½¿ç”¨éœ€è¦é«˜æ–¯æ ¸å‡½æ•°ï¼ˆRBFï¼‰ï¼š
                
      $$K_\gamma(\vec{x}_{i}, \vec{x}_{j})=e^{-\gamma\|\vec{x}_{i}-\vec{x}_{j}\|^2}$$                
                å…¶ä¸­ï¼Œ$\|\vec{x}_{i}-\vec{x}_{j}\|^2$ ä¸ºä¸¤ç‚¹é—´è·ç¦»çš„å¹³æ–¹ï¼Œ$K_\gamma$ åæ˜ äº†ä¸¤å‘é‡ç›¸ä¼¼åº¦çš„å¤§å°ï¼Œ$\gamma$  åæ˜ äº†æ ¸å‡½æ•°å¯¹ç›¸ä¼¼åº¦çš„åˆ¤å®šæ ‡å‡†ã€‚
                
                ä¸¤å‘é‡ç‚¹è·ç¦»è¶Šè¿œï¼Œç›¸ä¼¼åº¦è¶Šæ¥è¿‘ $0$ï¼Œä¸¤å‘é‡ç‚¹è·ç¦»è¶Šè¿‘ï¼Œç›¸ä¼¼åº¦è¶Šæ¥è¿‘ $1$ï¼Œ
                
                $\gamma$ è¾ƒå°ï¼Œç›¸ä¼¼åº¦å˜åŠ¨è¿Ÿé’ï¼Œ$\gamma$ è¾ƒå¤§ï¼Œç›¸ä¼¼åº¦å˜åŠ¨çµæ•ã€‚
                
                å…³äºä¸ºä½•é«˜æ–¯æ ¸å‡½æ•°å¯ä»¥è®¡ç®—æ— é™ç»´åº¦ä¸‹å‘é‡ç›¸ä¼¼åº¦çš„ç»“æœï¼Œæˆ‘ä»¬è½¬åŒ–æ ¸å‡½æ•°ä¸ºï¼š
                
      $$K_\gamma(\vec{x}_{i}, \vec{x}_{j})=e^{-\gamma\|\vec{x}_{i}-\vec{x}_{j}\|^2}=C\cdot e^{\vec{x_1}\cdot\vec{x_1}} \\ C=e^{-\gamma(\|x_i^2\|+\|x_j^2\|)}$$                
                æ¥ç€å¯¹ $e^{\vec{x_1},\vec{x_1}}$æ³°å‹’å±•å¼€ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
                
      $$K_\gamma(\vec{x}_{i}, \vec{x}_{j})=C\cdot e^{\vec{x_1}\cdot\vec{x_1}}=C\cdot\sum_{n=0}^\infty \frac{\vec{x}_{i}\cdot \vec{{x}_{j}}^n}{n!}=C\cdot\sum_{n=0}^\infty \frac{K_{0,n}(\vec{x}_{i}, \vec{x}_{j})}{n!}$$                
                æˆ‘ä»¬ç”±æ­¤å‘ç°é«˜æ–¯æ ¸å‡½æ•°ä¸ºæ‰€æœ‰ç»´åº¦ä»ä½åˆ°é«˜çš„è°ƒå‚ç»„åˆï¼Œè•´å«äº†æ‰€æœ‰ç»´åº¦ä¸‹å‘é‡ç‚¹ä¹˜çš„ä¿¡æ¯ï¼Œç”±æ­¤æˆ‘ä»¬å°†è¿™ä¸ªè•´å«æ‰€æœ‰ç»´åº¦ç‚¹ç§¯ä¿¡æ¯çš„å€¼ç§°ä¸ºæ— é™ç»´åº¦ä¸‹å‘é‡ç›¸ä¼¼åº¦ã€‚
                
            - è½¯é—´éš”
                
                <aside>
                ğŸ’¡ å½“å‡ºç°ç ´åé—´éš”çš„ç‚¹æ—¶ï¼Œé‡‡ç”¨é‡åŒ–è¯¯å·®è¡¡é‡è¶…å¹³é¢çš„é€‰å–
                
                </aside>
                
                å½“æ•°æ®ç‚¹åˆ†å¸ƒåˆ°é—´éš”å†…éƒ¨ï¼Œä¸ç¬¦åˆçº¦æŸæ¡ä»¶æ—¶ï¼Œæˆ‘ä»¬è®¡ç®—å®ƒä¸æ­£ï¼ˆè´Ÿï¼‰è¶…å¹³é¢ $\vec{x}\cdot\vec{w}+b=\pm 1$ çš„è·ç¦»ï¼Œå°†å…¶ä½œä¸ºä¸€ä¸ªå¯é‡åŒ–çš„è¯¯å·®ï¼š
                
      $$\epsilon_i=max(0, 1-y_i\cdot(\vec{x}\cdot W+B))$$                
                æˆ‘ä»¬å‘åŸè¶…å¹³é¢ç¡¬é—´éš”æ±‚è§£ä¸­å¼•å…¥æŸå¤±å€¼çš„æ¦‚å¿µï¼Œå¾—åˆ°é—®é¢˜ï¼š
                
      $$J(\vec{w})_{min}= \ min_{\vec{w}, b}\left(\frac{1}{2}\cdot\|\vec{w}\|^2+\sum_{i=1}^N  \epsilon_i \right)\\  \ s.t. \ \  g_i(\vec{w}, b)= y_i\left( W\cdot \vec{x}_{i}+B \right) > 1$$                
                å…¶ä¸­ï¼Œ$\epsilon_i= \max(0, 1-y_i\cdot(\vec{x}\cdot W+B))$ ä¸ºé“°é“¾æŸå¤±å‡½æ•°ã€‚ç”±äº$\|\vec{w}\|$ è¶Šå¤§ï¼Œé—´éš”è¶Šå°ï¼Œè¶Šä¸èƒ½å‡ºé”™ï¼Œ$\epsilon_i$ è¶Šå°ï¼Œåä¹‹äº¦ç„¶ã€‚å› æ­¤ $\|\vec{w}\|$ ä¸ $\epsilon_i$ ç›¸äº’åˆ¶çº¦ï¼Œè¾¾åˆ°å¹³è¡¡ã€‚
                
                $J(\vec{w})$ ä¸­çš„ $\epsilon_i$ ä½œä¸ºè‡ªå˜é‡å‡ºç°æ—¶ï¼Œæˆ‘ä»¬å°† $\epsilon_i$ çš„è§£æå¼è½¬åŒ–ä¸ºä¸¤ä¸ªçº¦æŸæ¡ä»¶ï¼š
                
                1. $\epsilon_i \geq1-y_i\cdot(\vec{x}\cdot W+B)$
                2. $\epsilon_i \geq 0$
                
                ä»¥åŠå…ˆå‰çš„å‡ ä¸ªçº¦æŸæ¡ä»¶ï¼š
                
                1. $\lambda_i \geq 0$
                2. $\lambda_i[y_i\left(W\cdot \vec{x}_{i}+B\right)-1+\epsilon_i]=0$
                
                åœ¨å®é™…æ“ä½œä¸­ï¼Œå¯ä»¥åœ¨æŸå¤±å€¼å‰ä¹˜ $C$ï¼Œæ§åˆ¶æŸå¤±å€¼å¯¹è¶…å¹³é¢é€‰å–çš„å½±å“ã€‚æœ€ååˆ©ç”¨å¦‚ä¸Šçº¦æŸæ¡ä»¶ï¼Œå†åˆ©ç”¨å¯¹å¶æ€§è§£å‡ºè½¯é—´éš”ä¸‹è¶…å¹³é¢ï¼Œå¾—åˆ°é—®é¢˜ï¼š
                
      $$q(\lambda_i)_{max}=\left[\sum_{i=1}^{N} \lambda_{i}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda _j y_{i} y_{j} (\vec{x}_{i}\cdot \vec{x}_{j})\right]_{max}\\ s.t. \ \ \sum_{i=1}^N \lambda_iy_i=0,0 \leq \lambda_i \leq C$$                
            - æ‹‰æ ¼æœ—æ—¥å¯¹å¶ä¼˜åŒ–æ±‚è§£
                
                <aside>
                ğŸ’¡ åˆ©ç”¨ä¼˜åŒ–é—®é¢˜å¼ºå¯¹å¶æ€§ï¼Œæ„é€ åŸå‡½æ•°çš„ä¸‹ç•Œå‡½æ•° $q(\lambda_i)_{max}$ï¼Œä¾§é¢æ±‚å¾—ç»“æœ
                
                </aside>
                
                æˆ‘ä»¬æ±‚è§£è¶…å¹³é¢çš„çš„åŸå§‹æ–¹æ³•ä¸ºï¼š
                
      $$J(\vec{w})_{min}=min_{\vec{w}, b}(\frac{1}{2}\cdot\|\vec{w}\|^2) \\ s.t. \ \ g_i(\vec{w}, b)=y_i\left( W\cdot \vec{x}_{i}+B \right) > 1$$                
                å…¶ä¸­ï¼Œè¶…å¹³é¢çš„æœ€ä¼˜è§£åœ¨ $\vec{w}^*,b^*$ å¤„å–å¾—ã€‚
                
                æˆ‘ä»¬å®šä¹‰æ–°æ–¹ç¨‹ï¼Œ$q(\lambda_i):=L(\vec{w},b,\lambda_i)_{min}\leq J(\vec{w^*})-\sum_{i=1}^{N}\lambda_i g_i(\vec{w^*}, b^*)$
                
                å› ä¸º $\lambda_i\geq0$ï¼Œ $g_i(\vec{w}, b) \geq 0$ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸ç­‰å¼ï¼š
                
      $$q(\lambda_i)\leq J(\vec{w^*})-\sum_{i=1}^{N}\lambda_i g_i(\vec{w^*}, b^*)\leq J(\vec{w^*})\leq J(\vec{w})$$                
                å› æ­¤æˆ‘ä»¬å¯ä»¥çœ‹å‡º $q(\lambda_i)$ æ˜¯ $J(\vec{w})$ çš„ä¸‹ç•Œï¼Œæˆ‘ä»¬è¿˜æœ‰ä¸ç­‰å¼ï¼š
                
      $$q(\lambda_i)\leq q(\lambda^*_i)\leq J(\vec{w^*})\leq J(\vec{w})$$                
                å¦‚æœ $q(\lambda^*_i)< J(\vec{w^*})$ï¼Œåˆ™ä¸ºå¼±å¯¹å¶é—®é¢˜ï¼Œä½†å¦‚æœ $q(\lambda^*_i)= J(\vec{w^*})$ï¼Œä¸ºå¼ºå¯¹å¶é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥æ±‚è§£å¯¹å¶é—®é¢˜ï¼Œæ­¤æ—¶åŸé—®é¢˜ä¸å¯¹å¶é—®é¢˜ä¼šåŒæ—¶è§£å†³ï¼Œæˆ‘ä»¬å¯»æ‰¾ä¸‹ç•Œ $q(\lambda_i)$ çš„æœ€å¤§å€¼ $q(\lambda^*_i)$ æ—¶ï¼Œå°±åŒæ—¶æ‰¾åˆ°äº† $J(\vec{w})$ çš„æœ€å°å€¼ $J(\vec{w^*})$ï¼Œå³ $J(\vec{w})_{min}$ã€‚
                
                å› ä¸ºåŸé—®é¢˜æ»¡è¶³$Slater$æ¡ä»¶ï¼Œå› æ­¤ä¸ºå¼ºå¯¹å¶é—®é¢˜ï¼Œæˆ‘ä»¬æ„é€ å‡ºåŸé—®é¢˜çš„å¯¹å¶é—®é¢˜ï¼š
                
      $$q(\lambda_i)_{max}=\left[L(\vec{w},b,\lambda_i)_{min} \right]_{max}\\ s.t. \ \ \lambda_i\geq0$$                
                æˆ‘ä»¬å…ˆæ±‚è§£ $L(\vec{w},b,\lambda_i)_{min}$ï¼š
                
      $$L(\vec{w},b,\lambda_i)_{min}=\frac{\| \vec{w}\|^2}{2}-\sum_{i=1}^{N} \lambda_{i}\left(y_{i}\left(\vec{w} \cdot \vec{x_{i}}+b\right)-1\right)$$                
                åŒ–ç®€è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¥—ç”¨å¦‚ä¸‹ $KKT$ æ¡ä»¶ï¼š
                
                1.  $\vec{w}-\sum_{i=1}^{N}\lambda_i\cdot y_i \cdot x_i=0$
                2. $\sum_{i=1}^{N}\lambda_i\cdot y_i=0$
                
                ä»£å…¥åŸå¼ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
                
      $$\begin{aligned}L(\vec{w},b,\lambda_i)_{min}=\ & \frac{1}{2}\left(\sum_{i=1}^{N} \lambda_{i} y_{i} \vec{x}_{i}\right) \left(\sum_{i=1}^{N} \lambda_{j} y_{j} \vec{x}_{j}\right) -\\ & \sum_{i=1}^{N} x_{i} \left(y_{i} \left(\left(\sum_{j=1}^{N} \lambda_jy_{j}\vec{x}_{j}\right) \vec{x}_{i}+b\right)-1\right)\\=\ & \sum_{i=1}^{N} \lambda_{i}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda _j y_{i} y_{j} \vec{x}_{i} \vec{x}_{j}\end{aligned}$$                
                äºæ˜¯åŸé—®é¢˜çš„å¯¹å¶é—®é¢˜è½¬æ¢æˆï¼š
                
      $$q(\lambda_i)_{max}=\left[\sum_{i=1}^{N} \lambda_{i}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \lambda_{i} \lambda _j y_{i} y_{j} (\vec{x}_{i}\cdot \vec{x}_{j})\right]_{max}\\ s.t. \ \ \lambda_i\geq0$$                
                æˆ‘ä»¬è§£å‡ºå–æå€¼æ—¶ $\lambda_i$ çš„å€¼ï¼Œåˆ©ç”¨ $KKT$ æ¡ä»¶ï¼Œæ±‚å‡º$\vec{w}=\sum_{i=1}^{N}\lambda_i\cdot y_i \cdot x_i$
                
                è€Œä¸”å¯¹äºæ‰€æœ‰å‘é‡è€Œè¨€ï¼Œåªæœ‰æ”¯æŒå‘é‡ $\vec{x_i}\in B$ï¼Œ$\lambda_i \neq 0$ï¼Œå› æ­¤åªæœ‰æ”¯æŒå‘é‡å‚ä¸åˆ°å¯¹å¶é—®é¢˜çš„è®¡ç®—ä¹‹ä¸­ã€‚
                
        - å‚è€ƒé“¾æ¥
            
            [çœ‹äº†è¿™ç¯‡æ–‡ç« ä½ è¿˜ä¸æ‡‚SVMä½ å°±æ¥æ‰“æˆ‘](https://zhuanlan.zhihu.com/p/49331510)
            
            [æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰--åŸç†ç¯‡](https://zhuanlan.zhihu.com/p/31886934)
            
            [Karush-Kuhn-Tucker (KKT)æ¡ä»¶](https://zhuanlan.zhihu.com/p/38163970)
            
    - é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰
        
        <aside>
        ğŸ’¡ é«˜æ–¯æ··åˆæ¨¡å‹æ˜¯åˆ†ç±»æ¨¡å‹ï¼Œå¤„ç†åŒä¸€é›†åˆä¸‹çš„æ•°æ®åŒ…å«å¤šç§ä¸åŒåˆ†å¸ƒçš„æƒ…å†µ
        
        </aside>
        
        - æ•°å­¦åŸç†åˆ†æ
            
            é«˜æ–¯æ··åˆæ¨¡å‹çš„æœ¬è´¨æ˜¯ä¸€ä¸ªæ··åˆæ¦‚ç‡åˆ†å¸ƒï¼š
            
      $$P(x)=\sum_{k=1}^KW_k\cdot \phi(x\mid\mu_k,Cov_k)$$            
            å…¶ä¸­ï¼Œ$k$ ä¸º GMM æ¨¡å‹ä¸­æˆåˆ†ä¸ªæ•°ï¼Œ$\phi(x)$ ä¸ºé«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œåˆ†å¸ƒçš„å‡å€¼ä¸º $\mu_k$ï¼Œå…¶åæ–¹å·®çŸ©é˜µä¸º ${Cov}_k$ï¼Œ$W_k$ ä¸ºå„æˆåˆ†æƒé‡ã€‚
            
            æˆ‘ä»¬æƒ³è¦å°†æ•°æ®åˆ†ä¸º $n$ ç±»ï¼Œå³ç°‡æ•° $K=n$ï¼Œè®¡ç®— $\vec{x}=(\mu_k,\theta_k,W_k)ï¼Œk\in[1,K]$  
            
            æœ€ç»ˆä»å…¨ä½“æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒ $P(x)$ ä¸­æ‘˜å‡º $n$ ä¸ªæ­£æ€åˆ†å¸ƒï¼Œåˆ†åˆ«è¡¨ç¤º $n$ ç±»æ•°æ®ã€‚
            
            å¯¹äºå‚æ•°çš„æ±‚è§£ï¼Œæˆ‘ä»¬ä½¿ç”¨ EM ç®—æ³•ï¼Œå³æœ€å¤§ä¼¼ç„¶ç®—æ³•ï¼š
            
            æˆ‘ä»¬å†™å‡ºæ¦‚ç‡å‡½æ•° $P(x)$ çš„ä¼¼ç„¶å‡½æ•°ï¼š
            
      $$L(\theta)=\prod_{i=1}^{n}[\sum_{j=1}^{n} W_j\phi(x|\mu_j,Cov_j)]$$            
            ç®€åŒ–åæ–¹å·®çŸ©é˜µ $Cov_k$ ä¸º $\sigma_k$ï¼Œç­‰å¼ä¸¤ä¾§å–å¯¹æ•°ï¼š
            
      $$l(\theta)=\ln(L(\theta))=\sum_{i=1}^{n}\ln[\sum_{j=1}^{n} W_j\phi(x|\mu_j,\sigma_j)]$$            
            ç­‰å¼ä¸¤ä¾§æ±‚åå¯¼æ•°ï¼š
            
      $$\frac{\partial l}{\partial \mu}=$$            
      $$\frac{\partial l}{\partial \sigma}=$$            
            é«˜æ–¯æ··åˆæ¨¡å‹ä¸åªæ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼Œä¹Ÿæ˜¯ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ã€‚æˆ‘ä»¬åœ¨å°†æ•°æ®åˆ†ç±»ä¸º $n$ ä¸ªé«˜æ–¯åˆ†å¸ƒä¹‹åï¼Œä¹Ÿå˜ç›¸æ„é€ äº†ä¸€ä¸ªå åŠ çš„æ€»æ¦‚ç‡åˆ†å¸ƒã€‚åˆ©ç”¨è¿™ä¸ªå åŠ çš„æ€»æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨å®ƒæ¥ç”Ÿæˆæ–°æ•°æ®ã€‚
            
    - éšé©¬å°”å¯å¤«æ¨¡å‹ï¼ˆHMMï¼‰
        - æ•°å­¦åŸç†åˆ†æ
    - æ··æ·†çŸ©é˜µï¼ˆConfusion Matrixï¼‰
        - å…·ä½“æ“ä½œæ­¥éª¤
            
            ç”Ÿæˆå†³ç­–æ ‘çš„æ··æ·†çŸ©é˜µ
            
            ```python
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(data_o, pred_tree)
            print(cm)
            ```
            
        - æ•°å­¦åŸç†åˆ†æ
            
            å¯¹äºç±»åˆ«åˆ†æï¼Œæˆ‘ä»¬æœ‰é¢„æµ‹çš„ç±»åˆ«ä¸å®é™…çš„ç±»åˆ«ï¼Œåˆ©ç”¨é¢„æµ‹ç±»åˆ«å’Œå®é™…ç±»åˆ«ï¼Œæ„å»ºæ··æ·†çŸ©é˜µï¼Œåˆ¤æ–­åˆ†ç±»çš„ç²¾ç¡®ç¨‹åº¦ï¼Œä»¥å¦‚ä¸‹æ•°æ®ä¸ºä¾‹ï¼š
            
            |  | é¢„æµ‹ä¸º A ç±» | é¢„æµ‹ä¸º B ç±» | é¢„æµ‹ä¸º C ç±» | é¢„æµ‹ä¸º D ç±» |
            | --- | --- | --- | --- | --- |
            | å®é™…ä¸º A ç±» | 12 | 4 | 3 | 6 |
            | å®é™…ä¸º B ç±» | 3 | 10 | 5 | 3 |
            | å®é™…ä¸º C ç±» | 4 | 3 | 8 | 0 |
            | å®é™…ä¸º D ç±» | 5 | 2 | 4 | 11 |
            
      $$Con = \left(\begin{array}{cccc}12 & 4 & 3 & 6 \\ 3 & 10 & 5 & 3 \\ 4 & 3 & 8 & 0 \\ 5 & 2 & 4 & 11\end{array}\right)$$            
            å…¶ä¸­ï¼Œæ··æ·†çŸ©é˜µæ­£å¯¹è§’çº¿å€¼è¶Šå¤§ï¼Œå…¶ä»–å€¼è¶Šå°ï¼Œé¢„æµ‹æ•ˆæœçº¦å®Œç¾ã€‚
            
            å³å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰è¶Šé«˜ï¼Œæ•´ä½“é¢„æµ‹æ•ˆæœè¶Šå¥½ï¼š
            
      $$A=\frac{\sum_{i=1}^{N}Con_{ii}}{\sum_{i=1}^{N}\sum_{j=1}^{N}{Con_{ij}}}$$            
            é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªå¯¹åº”æŒ‡æ ‡æ¥æ›´åŠ ç»†èŠ‚åœ°è¡¡é‡é¢„æµ‹æ•ˆæœï¼š
            
            1. ç²¾ç¡®åº¦ï¼ˆPrecisionï¼‰
                
                ç²¾ç¡®åº¦æ˜¯å¯¹äºæˆ‘ä»¬çš„é¢„æµ‹ç»“æœè€Œè¨€çš„ï¼Œæœ‰å¤šå°‘é¢„æµ‹æ­£ç¡®äº†ã€‚
                
                å³å¯¹äºæŸä¸€ä¸ªç±»åˆ« $E$ è€Œè¨€ï¼Œé¢„æµ‹ä¸º $E$ ç±»çš„æ ·æœ¬ä¸­æœ‰å¤šå°‘å®é™…å±äº $E$ ç±»ï¼š
                
      $$P_I=\frac{Con_{ii}}{\sum_{n=1}^{N}{Con_{ni}}}$$                
                å…¶ä¸­ï¼Œå‡å®šæ··æ·†çŸ©é˜µä¸­ $I$ ç±»ç›¸å…³å…ƒç´ å¤„äºç¬¬ $i$ è¡Œåˆ—ï¼Œæ··æ·†çŸ©é˜µçš„å¤§å°ä¸º $N\times N$ã€‚
                
            2. å¬å›ç‡/çµæ•åº¦ï¼ˆRecallï¼‰
                
                å¬å›ç‡æ˜¯å¯¹äºåŸæœ¬å¸¦æ ‡ç­¾çš„æ•°æ®è€Œè¨€çš„ï¼Œæœ‰å¤šå°‘è¢«é¢„æµ‹æ­£ç¡®ã€‚
                
                å³å¯¹æ‰€æœ‰å®é™…ä¸º $E$ ç±»åˆ«çš„æ ·æœ¬è€Œè¨€ï¼Œæœ‰å¤šå°‘æ­£ç¡®çš„é¢„æµ‹ä¸ºäº† $E$ ç±»ï¼š
                
      $$R_I=\frac{Con_{ii}}{\sum_{n=1}^{N}{Con_{in}}}$$                
            3. åŒæ—¶è€ƒè™‘ä¸¤ä¸ªæŒ‡æ ‡ï¼Œæˆ‘ä»¬æœ‰ $F1$ åˆ†æ•°å¦‚ä¸‹ï¼š
                
      $$F_1=\frac{1}{\frac{1}{P_I}+\frac{1}{R_I}}$$                
                ç”±æ­¤å¯è§ï¼Œæ­¤è°ƒå’Œå¹³å‡æ•°è¶Šé«˜ï¼Œé¢„æµ‹æ•ˆæœè¶Šå¥½ã€‚ç”±äºè°ƒå’Œå¹³å‡çš„ç‰¹æ€§ï¼Œ$F1$ åˆ†æ•°å°†æ›´æ¥è¿‘ä¸¤ç§æŒ‡æ ‡ä¸­ç›¸å¯¹è¾ƒå°çš„é‚£ä¸€ä¸ªï¼Œè€Œéå•çº¯çš„äºŒè€…å¹³å‡å€¼ã€‚
                
    - è®­ç»ƒèµ„æ–™åˆ†å‰²ä¸é¢„æµ‹èƒ½åŠ›è¯„ä¼°
        - å…·ä½“æ“ä½œæ­¥éª¤
            1. å°†èµ„æ–™åˆ†è£‚æˆè®­ç»ƒèµ„æ–™ä¸è¯„ä¼°èµ„æ–™
                
                ```python
                from sklearn.model_selection import train_test_split
                x_train, x_test, y_train, y_test = train_test_split(features,data_o)
                ```
                
            2. åˆ©ç”¨è®­ç»ƒèµ„æ–™å»ºæ„æ¨¡å‹ï¼Œæ­¤å¤„ä¸ºå†³ç­–æ ‘
                
                ```python
                from sklearn.tree import DecisionTreeClassifier, export_graphviz
                clf = DecisionTreeClassifier(max_depth=2)
                clf = clf.fit(x_train, y_train)
                ```
                
            3. è¯„ä¼°ç²¾ç¡®åº¦
                
                ```python
                from sklearn.metrics import confusion_matrix
                
                # è¨ˆç®—åˆ†æ•¸
                score = clf.score(x_test, y_test)
                print("åˆ†æ•¸:",score)
                
                # ç”¢ç”Ÿæ··æ·†çŸ©é™£
                pred_tree = clf.predict(x_test)
                cm = confusion_matrix(y_test, pred_tree)
                print("æ··æ·†çŸ©é™£")
                print(cm)
                ```
                
- å›å½’è¿‡ç¨‹
    
    <aside>
    ğŸ’¡ ä¸€èˆ¬æ¥è¯´ï¼Œåˆ†ç±»çš„è¾“å‡ºæ˜¯ç¦»æ•£çš„ï¼Œè€Œå›å½’çš„è¾“å‡ºæ˜¯è¿ç»­çš„
    
    </aside>
    
    - å¤šå…ƒå˜é‡çº¿æ€§å›å½’ï¼ˆMLRï¼‰
        - å…·ä½“æ“ä½œæ­¥éª¤
            
            ```r
            # é”€å”®æ¸ é“ä¸é”€é‡çš„çº¿æ€§ç›¸å…³ï¼Œmarketing ä¸ºå››åˆ—çš„è¡¨æ ¼
            model <- lm(sales ~ youtube + facebook + newspaper, data = marketing)
            summary(model)
            ```
            
        - æ•°å­¦åŸç†åˆ†æ
            
            æˆ‘ä»¬æœ‰ $n$ ä¸ªå¯æ§å˜é‡ï¼ˆExplanatory Variablesï¼‰$x_1,x_2,\cdots,x_n$ï¼Œä¸€ä¸ªå› å˜é‡ ï¼ˆDependent Variableï¼‰$y$ï¼Œå‡å®šå¯æ§å˜é‡ä¸å› å˜é‡é—´ç¬¦åˆä¸€æ¬¡çº¿æ€§è§„å¾‹ï¼Œæˆ‘ä»¬æœ‰ï¼š
            
      $$y_i=c_0+c_1\cdot x_{1_i}+c_2\cdot x_{2_i}+\cdots+c_n\cdot x_{n_i}$$            
            - æ¦‚ç‡è®ºè¯ é‡Š
                
                å¯¹äºäºŒå…ƒçº¿æ€§å›å½’ï¼Œæˆ‘ä»¬æƒ³è¦å¾—åˆ° $y=b_0+b_1x$ï¼Œå°†å®é™…æ•°æ® $y_i$ ä¸ä¼°è®¡æ•°æ® $b_0+b_1x_1$ çºµå‘ç›¸å‡ï¼Œå¹³æ–¹æ±‚å’Œï¼Œå¾—åˆ°äºŒä¹˜æ³•ï¼š
                
      $$L(b_0,b_1)=\sum_{i=1}^n[y_i-(b_0+b_1x_i)]^2$$                
                æ±‚è§£æœ€å°äºŒä¹˜æ³•ï¼Œå¾—åˆ° $b_0$ ä¸ $b_1$ çš„æœ€ä¼˜å‚é‡ $\beta_0$ ä¸ $\beta_1$ï¼š
                
      $$\beta_0,\beta_1=\argmax_{b_0,b_1}L(b_0,b_1)$$                
                é€šè¿‡å¯¹ $L(b_0,b_1)$ å…³äº  $b_0$ ä¸ $b_1$ æ±‚åå¯¼ï¼Œå¾—åˆ°æœ€ä¼˜å‚é‡ï¼š
                
      $$\begin{aligned}&\hat \beta_1=\frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sum_{i=1}^n(x_i-\bar x)^2}\\&\hat \beta_0=\bar y-\hat \beta_1\cdot \bar x\end{aligned}$$                
            - çº¿æ€§ä»£æ•°è¯ é‡Š
                
                å¯¹äºä»»ä¸€çº¿æ€§ç³»ç»Ÿï¼ˆLinear Systemï¼‰ï¼Œæˆ‘ä»¬æœ‰ï¼š
                
      $$A_{m\times n}\cdot \vec x=\vec y$$                
                å…¶ä¸­ï¼Œ$\vec x\in R^n$ï¼Œ$\vec y\in R^m$ ï¼Œ$A_{m\times n}$ ä¸ºçº¿æ€§å˜æ¢çš„åŸºæœ¬çŸ©é˜µï¼ˆElementary Matrixï¼‰
                
                å½“çº¿æ€§ç³»ç»Ÿæ— è§£æ—¶ï¼Œæˆ‘ä»¬å¯»æ‰¾è¿‘ä¼¼è§£ $A_{m\times n}\cdot \vec s\approx\vec b$ï¼Œæœ¬è´¨ä¸Šå¯»æ‰¾ä¸€ä¸ª $\vec s$ï¼Œä½¿å¾—ä¸¤å‘é‡ $A\vec s$ ä¸ $\vec b$ è·ç¦»æœ€è¿‘ï¼š
                
      $$l=\min_{\vec s}\Vert A\vec s-\vec b \Vert$$                
                ç›¸å½“äºå¯»æ‰¾ä¸¤å‘é‡æ‰€æœ‰å…ƒä¹‹é—´å·®çš„å¹³æ–¹å’Œï¼š
                
      $$l=\min_{\vec s}\sum_{i=1}^m [(A \vec s)_i-\vec b_i]^2$$                
                æˆ‘ä»¬è®¡ç®— $A^TA\vec s=A^T\vec b$ï¼Œä¸€å®šèƒ½å¾—åˆ°è§£ $\vec s$ ä½œä¸ºæœ€å°äºŒä¹˜çš„è¿‘ä¼¼è§£ã€‚
                
                - å¯¹æ­¤çš„è¯æ˜ï¼Œæˆ‘ä»¬ä»æ­£äº¤æŠ•å½±çš„è§’åº¦å‡ºå‘
                    
                    å› ä¸º $A\vec x\in\text{Col(A)}$ï¼Œåœ¨ $\text{Col(A)}$ å†…ä¸ $\vec b$ è·ç¦»æœ€è¿‘å‘é‡ä¸º $A\vec s=\text{Proj}_{\text{Col(A)}}\vec b$ï¼Œå…·ä½“æ¥è¯´ï¼Œ æˆ‘ä»¬æœ‰ï¼š
                    
      $$\vec b-\hat b\in \text{Col}(A)^\perp=\text{Nul}(A^T)$$                    
                    å…¶ä¸­ï¼Œ$\hat b=\text{Proj}_{\text{Col(A)}}\vec b$ï¼Œä½œä¸º $\vec b$ åœ¨ $\text{Col}(A)$ ä¸Šçš„æ­£äº¤æŠ•å½±å‘é‡ã€‚
                    
                    ç”±ä¸Šå¯çŸ¥ $A^T\cdot(\vec b-\hat b)=0$ï¼Œå› æ­¤ $\vec b=\hat b$ï¼Œä¸‹é¢ä»ä¸¤ä¸ªæ–¹å‘è¯æ˜åŸå¼ã€‚
                    
                    ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬è®¾ $\vec s\in R^n$ ä¸ºæœ€å°äºŒä¹˜ç»“æœï¼Œé‚£ä¹ˆæœ‰ï¼š
                    
      $$A\vec s=\hat b=\vec b \Rightarrow A^TA\vec s=A^T\vec b$$                    
                    å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæˆ‘ä»¬è®¡ç®— $A^TA\vec s=A^T\vec b$ ï¼Œé‚£ä¹ˆæœ‰ï¼š
                    
      $$A^TA\vec s=A^T\vec b\Leftrightarrow A^T(\vec b-A\vec s)=0$$                    
                    å› æ­¤ $\vec b-A\vec s\in \text{Nul}(A^T)=\text{Col}(A)^\perp$ï¼Œ$A\vec s\in\text{Col}(A)$
                    
                    ç”±äºæ­£äº¤æŠ•å½±å‘é‡å”¯ä¸€ç¡®å®šï¼Œæ‰€ä»¥ $A \vec s=\hat b$
                    
                    å› æ­¤ï¼Œ$A \vec s=\hat b$ çš„è§£ä¸ $A^TA\vec s=A^T\vec b$ çš„è§£å®Œå…¨ç›¸åŒã€‚
                    
    - æ”¯æ´å‘é‡æœºæ—¶åºå›å½’ï¼ˆSVRï¼‰
        - å…·ä½“æ“ä½œæ­¥éª¤
        - æ•°å­¦åŸç†åˆ†æ
            
            å¯¹äºå›å½’é—®é¢˜ï¼Œç»™å®šè®­ç»ƒç”¨å‘é‡é›†åˆ $D=\{(x_1,y_1),(x_2,y_2)\cdots(x_n,y_n)\}$
            
            æˆ‘ä»¬å¸Œæœ›å­¦ä¹ å¾—åˆ°ä¸€ä¸ªå›å½’æ¨¡å‹ $f_{w,b}(x)=w^Tx+b$ï¼Œä½¿å¾— $x_i \approx y_i$ã€‚
            
            ä¼ ç»Ÿå›å½’æ¨¡å‹è®¡ç®— $\epsilon=f_{w,b}(x_i)-y_i, \ \epsilon \rightarrow 0$ï¼Œä½œä¸ºæŸå¤±å€¼ï¼Œåªæœ‰è¾“å‡ºå€¼ $f_{w,b}(x_i)$ ä¸çœŸå®å€¼ $y_i$ ç›¸åŒæ—¶ï¼ŒæŸå¤±å€¼æ‰ä¸º $0$ã€‚
            
            è€Œåœ¨ SVR æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬è§„å®šä¸€ä¸ªå¯å®¹å¿çš„è¯¯å·®å¤§å° $\epsilon_{base}$ï¼Œå½“ $|f_{w,b}(x_i)-y_i|=\epsilon \leq \epsilon_{base}$ æ—¶ï¼Œè¯¯å·®å¤„äºå¯å®¹å¿çš„èŒƒå›´å†…ï¼Œåªæœ‰ $\epsilon_{base}<\epsilon$ æ—¶ï¼Œæˆ‘ä»¬æ‰è®¡ç®—æŸå¤±ã€‚
            
            å¯¹æ­¤ï¼Œæˆ‘ä»¬æ„å»ºæ­£åˆ™åŒ–å‡½æ•° $l_\epsilon$ï¼š
            
      $$\begin{aligned}    l_\epsilon(x)=   \begin{cases}   0&|x| <\epsilon   \,\\ |x|-\epsilon &|x|\geq \epsilon  \end{cases}  \end{aligned}$$            
            ç”±æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°é—®é¢˜ï¼š
            
      $$min_{w,b}\left(\frac{1}{2}\|w\|^2+C\cdot \sum_{i=1}^N l_\epsilon(f(x_i)-y_i)\right)\\f= X^T\cdot\vec{w}+b=0$$            
            å¯¹ $l_\epsilon(f(x_i)-y_i)$ å‡½æ•°ï¼Œå½“è¾“å…¥å¤§äºå¯å®¹å¿è¯¯å·®æ—¶ï¼Œè¿”å›è¾“å…¥ä¸å¯å®¹å¿è¯¯å·®çš„å·®ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥ä¸¤ä¸ªæ¾å¼›å˜é‡ï¼Œå°†è¯¥å‡½æ•°éé›¶è¾“å‡ºçš„å€¼æ¶ˆè§£ï¼š
            
      $$f(x_i)-y_i>\epsilon>0, \ f(x_i)-y_i-\epsilon = \xi_i\\ y_i-f(x_i)>\epsilon>0, \ y_i-f(x_i)-\epsilon = \hat\xi_i$$            
            å¯¹è¾“å…¥å°äºå¯å®¹å¿è¯¯å·®çš„æƒ…å†µï¼Œæˆ‘ä»¬æ·»åŠ çº¦æŸæ¡ä»¶ $\xi_i \geq 0, \hat\xi_i \geq 0$ï¼Œé™åˆ¶ $\xi_i$ éè´Ÿï¼Œè¿™æ ·å°±è§£å†³äº†å‡ºç°è´Ÿçš„æ¾å¼›å˜é‡çš„æƒ…å†µï¼Œè§£å†³äº† $l_\epsilon$  å‡½æ•°é›¶è¾“å‡ºå€¼çš„éƒ¨åˆ†ï¼Œç›´æ¥åˆ©ç”¨çº¦æŸæ¡ä»¶å°†å…¶èˆå¼ƒã€‚
            
            äºæ˜¯æˆ‘ä»¬å°†åŸé—®é¢˜é‡å†™ä¸ºçº¦æŸå‘é‡å½¢å¼ï¼š
            
      $$min_{w,b}\left(\frac{1}{2}\|w\|^2+C\cdot \sum_{i=1}^N (\xi_i+\hat\xi_i)\right)\\ \begin{aligned} s.t. \  \ f(x_i)-y_i&\leq\epsilon + \xi_i \\ y_i-f(x_i)&\leq\epsilon + \hat\xi_i \\ \xi _i&\geq 0 \\ \hat\xi_i &\geq 0\end{aligned}$$            
            æˆ‘ä»¬åˆ©ç”¨ä¸ç­‰å¼çº¦æŸçš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•è®¡ç®—æœ€å°å€¼ï¼š
            
      $$$$